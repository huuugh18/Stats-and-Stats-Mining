{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangular Data\n",
    "Spreadsheet or database table\n",
    "\n",
    "General Term for 2D matrix with rows indicating records (cases) and columns (features)\n",
    "\n",
    "**DataFrame** is the specific format in Python and R\n",
    "\n",
    "**Feature:** column within a table ---  **Records:** row within a table\n",
    "\n",
    "Features are used to predict a **target** (outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonrectangular Data\n",
    "#### Time Series Data\n",
    "#### Spatial Data  - mapping and location analytics\n",
    "#### Graph (network) Data\n",
    "Represent physical, social, or abstract relationships - social networks\n",
    "\n",
    "**Key Ideas**\n",
    "- The basic data structure in data science is a rectangular matrix in which rows are records and columns are variables (features). \n",
    "- Terminology can be confusing; there are a variety of synonyms arising from the different disciplines that contribute to data science (statistics, computer science, and information technology)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates of Location\n",
    "Variables with measured or count data might have thousands of distinct values. A basic step in exploring your data is getting a “typical value” for each feature (variable): an estimate of where most of the data is located (i.e., its central tendency).\n",
    "\n",
    "Key Terms:\n",
    "- **Trimmed mean** The average of all values after dropping a fixed number of extreme values. Synonym truncated mean \n",
    "    - eliminates influence of exttreme values\n",
    "    - Ex. used in figure skating judginig , remove top and bottom judge scores\n",
    "    - widely used - preferred over regular mean (tripe top and bottom 10%)\n",
    "\n",
    "- **Weighted mean** The sum of all values times a weight divided by the sum of the weights. \n",
    "    - Two Motivations:\n",
    "        - Some values are intrinsically more variable than others, and highly variable observations are given a lower weight. For example, if we are taking the average from multiple sensors and one of the sensors is less accurate, then we might downweight the data from that sensor\n",
    "        - data collected does not equally represent the different groups that we are interested in measuring. For example, because of the way an online experiment was conducted, we may not have a set of data that accurately reflects all groups in the user base. To correct that, we can give a higher weight to the values from the groups that were underrepresented\n",
    "- **Weighted median** The value such that one-half of the sum of the weights lies above and below the sorted data. \n",
    "    - sort data after applying the weights to get weighted median\n",
    "    - more robust to outliers\n",
    "  \n",
    "- **Robust** Not sensitive to extreme values. Synonym resistant \n",
    "\n",
    "#### Python Calcs\n",
    "Mean: `state['Pop'].mean()`\n",
    "\n",
    "Trim Mean: `trim_mean(state['Pop'], 0.1)`\n",
    "\n",
    "Median: `state['Pop'].median()`\n",
    "\n",
    "Weighted Meand and Median:\n",
    "- `np.average(state['Murder.Rate'], weights=state['Population'])`\n",
    "- `wquantiles.median(state['Murder.Rate'], weights=state['Population'])`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimates of Variability \n",
    "\n",
    "Standard deviation easier to interpret than variance since it's on same scale as original data\n",
    "\n",
    "#### Degrees of Freedom - n or n-1\n",
    "if use n - underestimate true value of variance and the standard deviation in pop\n",
    "biased estimate - divide by n-1 becomes unbiased\n",
    "\n",
    "## Estimates Based on Percentiles\n",
    "Look at spread of sorted data\n",
    "For very large datasets - computing exact percentiles very computationally expensive since involves sorting\n",
    "Software use special algorithms to get approx percentile within certain accuracy\n",
    "\n",
    "**Python Calcs**\n",
    "\n",
    "Quantiles: `state['Murder.Rate'].quantile([0.05,0.25, 0.5, 0.75, 0.95])`\n",
    "\n",
    "#### Histograms:\n",
    "\n",
    "`pandas.cut` creates a series that maps values into segments (this case 10)\n",
    "\n",
    "`binnedPop = pd.cut(state['Population'], 10)`\n",
    "\n",
    "`binnedPop.value_counts()`\n",
    "\n",
    "Pandas supports histograms for data frames with `DataFrame.plot.hist`\n",
    "\n",
    "`ax = (state['Pop'] / 1_000_000).plot.hist(figsize=(4,4))`\n",
    "\n",
    "`ax.set_xlabel('Pop (millions)')`\n",
    "\n",
    "#### Density Plot\n",
    "Shows distribution of data values as continuous line => smoothed histogram\n",
    "\n",
    "Pandas provides `density` method to create density plot\n",
    "\n",
    "`ax=state['Murder.Rate'].plot.hist(density=True, xlim=[0,12], bins=range(1,12))`\n",
    "\n",
    "`state['Murder.Rate'].plot.density(ax=ax)` ** ax=ax Plot functs take optional axis argument, cause plot to be added to same graph\n",
    "\n",
    "`ax.set_xlabel('Murder Rate (per 100,000)')`\n",
    "\n",
    "#### Key Ideas\n",
    "- freq histogram plots freq counts on y-axis and var vals on x-axis\n",
    "    - gives sense of distribution of data at a glance\n",
    "- boxplot gives quick sense of distribution\n",
    "    - used in side by side displays to compare distributions\n",
    "- density plot is smoothed version of histogram\n",
    "    - requires a function to est. plot based on data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Binary and Categorical Data (pp. 27)\n",
    "\n",
    "**Mode** simple summary stat for categorical data and generally not used for numeric\n",
    "\n",
    "#### Expected Value\n",
    "A special type of categorical data is data in which the categories represent or can be mapped to discrete values on the same scale. \n",
    "\n",
    "Form of weighted mean\n",
    "\n",
    "Ex. A marketer for a new cloud technology, offers two levels of service, one priced at $ 300 / month and another at $50/month. The marketer offers free webinars to generate leads, and the firm figures that 5% of the attendees will sign up for the $300 service, 15\\% will sign up for the $50 service, and 80% will not sign up for anything.This data can be summed up, for financial purposes, in a single “expected value,” which is a form of weighted mean, in which the weights are probabilities.\n",
    "\n",
    "Calculation:\n",
    "- multiply each outcome by its probability of occurence\n",
    "- sum these values\n",
    "- EV = 0.05x300 + 0.15x50 + 0.8x0 = 22.5\n",
    "\n",
    "## Correlation\n",
    "Positive Correlation: x increases and so does y\n",
    "Negative Correlation: x increases and y decreases\n",
    "\n",
    "**Correlation Coefficient:** extent to which numeric vars are associated with one another (-1 to 1)\n",
    "- Calculation: multiply deviations from mean for var 1 times those for var 2 / product of std devs\n",
    "- if association not linear - cor coef may not be useful\n",
    "\n",
    "**Correlation Matrix:** table where vars are shown on both rows and cols, cells are correlations b/w vars\n",
    "- Check pp. 32 for example of python code\n",
    "- `sklearn.covariance` offer many alternatives - corr coef sensitive to outliers\n",
    "\n",
    "**Scatterplot:** plot in which x-axis value of one variable and y-axis value of another\n",
    "\n",
    "`ax = telecom.plot.scatter(x='T', y='VZ', figsive=(4,4), marker='$\\u25EF$')`\n",
    "\n",
    "`ax.set_xlabel('ATT')`\n",
    "\n",
    "`ax.set_ylabel('VERIZON')`\n",
    "\n",
    "`ax.axhline(0, color='grey', lw=1)`\n",
    "\n",
    "`ax.axvline(0, color='grey', lw=1)`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring 2 or more vars\n",
    "**Contingency table:** A tally of counts between two or more categorical variables. \n",
    "\n",
    "**Hexagonal binning:** A plot of two numeric variables with the records binned into hexagons. \n",
    "\n",
    "**Contour plot:** A plot showing the density of two numeric variables like a topographical map. \n",
    "\n",
    "**Violin plot:**  Similar to a boxplot but showing the density estimate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
