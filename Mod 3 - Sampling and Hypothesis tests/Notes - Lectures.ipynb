{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Lecture 1 - Sampling and Hypothesis Testing\n",
    "\n",
    "### Random Sampling\n",
    "\n",
    "- A sample is a subset of data from a larger data set.\n",
    "- Statisticians call this larger data set the population.\n",
    "- **Random sampling** is a process in which each available member of the population being sampled has an equal chance of being chosen for the sample at each draw.\n",
    "- The sample that results is called a simple random sample.\n",
    "- **With Replacement:** observations are put back in the population after each draw for possible future reselection.\n",
    "- **Without Replacement:** observations once selected, are unavailable for future draws.\n",
    "\n",
    "### Bias\n",
    "\n",
    "refers to measurement or sampling errors that are systematic & produced by the measuremnet or sampling process  \n",
    "difference b/w random chance errors and bias errors  \n",
    "unbiased process will produce error, but random error not trending strongly in any direction  \n",
    "\n",
    "Idea of shooting a gun that misses 70% of the time high right\n",
    "\n",
    "### Random Selection\n",
    "- not always easy to generate random samples\n",
    "1. What is the population we have access to?\n",
    "2. With or without replacement?  \n",
    "\n",
    "**Stratified Sampling:**  \n",
    "population divided into 'strata' and random samples taken from each stratum  \n",
    "Need to have the same % of groups or classes represented as the population\n",
    "\n",
    "### Key Ideas\n",
    "\n",
    "- Even in era of big data, random sampling important\n",
    "- Bias occurs when measurements or observations systematically in error b/c not representative of full pop.\n",
    "- data quality over data quantity\n",
    "- random sampling can reduce bias and improve quality\n",
    "\n",
    "### Sampling Distribution of a Statistic\n",
    "\n",
    "- distribution of some sample stat over many samples drawn from same population\n",
    "- much of classical stats concerned with making inferences from (small) samples to (very large) populations\n",
    "\n",
    "### Key Terms\n",
    "\n",
    "**Sample Statistic:** metric calculated for sample data drawn from larger pop  \n",
    "**Data Distribution:** freq. distribution of individual values in a data set  \n",
    "**Sampling Distribution:** freq. distribution of sample stat over many samples  \n",
    "**Central Limit Theorem:** tendency of sampling distribution to take on a normal shape as sample size rises.  \n",
    "** Standard error:** the variability (st.dev) of a sample stat over many samples\n",
    "- different from st.dev which refers to variability of individual data values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Lecture 2 - Central Limit Theorem, Bootstrap and Confidence Intervals\n",
    "\n",
    "### Central Limit Theorem\n",
    "- numeric dataset\n",
    "- sufficient # of samples **with replacement** and calculate mean of each sample => means will approximate a **normal distribution**\n",
    "- the more samples and bigger samples => closer to normal distribution\n",
    "- mean of the means will approximate original dataset\n",
    "\n",
    "### Standard Error\n",
    "- sums up variability in the sampling distribution for a statistic\n",
    "- based on standard deviation 's' of the sample values and sample size 'n'\n",
    "- **SE = s/sqrt(n)**\n",
    "\n",
    "### Key Ideas\n",
    "- freq dist of sample stat tells us how that metric would turn out differently from sample to sample\n",
    "- sampling dist can be estimated via the **bootstrap** or formulas relying on **CLT**\n",
    "- standard error = key metric that sums up variability of a sample\n",
    "\n",
    "### The Bootstrap\n",
    "- easy and effective way to estimate sampling distribution\n",
    "- draw additional samples **with replacement** from the sample iteslf\n",
    "- recalculate the statistic or model of each resample\n",
    "- doesn't have assumptions about data or stat being normally distributed\n",
    "\n",
    "- **powerful tool for assessing variability of sampling statistic**\n",
    "- est. sampling distributions for stats where no math approximation developed\n",
    "- when applied to predictive models => aggregating multiple bootstrap predictions (**bagging**) outperforms use of a single model\n",
    "\n",
    "\n",
    "### Confidence Intervals (CIs)\n",
    "- help understand error in sample estimate\n",
    "- used to represent an est. as a range instead of a single number\n",
    "- **Confidence Level:** % of CIs, constructed in same way from the same pop, that are expected to contain the stat of interest\n",
    "- **Interval Endpoints:** top and bottom of the CI\n",
    "\n",
    "### Algorithm\n",
    "Given sample size 'n', and a sample stat of interest, algorithm for a bootstrap CI is:  \n",
    "\n",
    "1. Draw a random sample of size n with replacement from the data (a\n",
    "resample).\n",
    "2. Record the statistic of interest for the resample.\n",
    "3. Repeat steps 1–2 many (R) times.\n",
    "4. For an x% confidence interval, trim [(100-x)/2]% of the R\n",
    "resample results from either end of the distribution.\n",
    "5. The trim points are the endpoints of an x% bootstrap confidence\n",
    "interval.’\n",
    "\n",
    "### Interpretation\n",
    "- We are estimating a pop. parameter from a sample\n",
    "- we don't know if sample stat we estimated is <,>, = to pop parameter\n",
    "- We are NOT certain that our CI contains the pop paramater or NOT\n",
    "- CORRECT: \"**We are x% confident that our pop parameter is b/w the two endpoints of this interval**\"\n",
    "\n",
    "### Key Ideas\n",
    "- CIs typical way to present estimates as an interval range\n",
    "- More data you ahev - less variable a sample est will be\n",
    "- The lower the level of confidence you can tolerate, the narrower the CI will be\n",
    "- The Bootstrap is an effective way to construct CIs\n",
    "\n",
    "### Reading\n",
    "[Central Limit Theorom Investopedia](https://www.investopedia.com/terms/c/central_limit_theorem.asp)\n",
    "\n",
    "- CLT states that distribution of sample means approximates a normal distribution as sample size gets larger\n",
    "- sample sizes >= 30 considered sufficient for CLT to hold\n",
    "- average of sample means and st. devs will = pop. mean and st. developed\n",
    "- sufficiently large sample size can predict characteristics of a population accurately"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}