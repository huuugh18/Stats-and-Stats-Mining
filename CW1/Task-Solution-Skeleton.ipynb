{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore the data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Description   Level_1 Level_2  \\\n",
       "count                                               10637     10649   10649   \n",
       "unique                                               9677        15      39   \n",
       "top     glory gorg col fing complet outfit express moo...  B092BA29   2D5A3   \n",
       "freq                                                   24       900     797   \n",
       "\n",
       "       Level_3  \n",
       "count    10649  \n",
       "unique      43  \n",
       "top       28A7  \n",
       "freq       797  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10637</td>\n      <td>10649</td>\n      <td>10649</td>\n      <td>10649</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>9677</td>\n      <td>15</td>\n      <td>39</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>glory gorg col fing complet outfit express moo...</td>\n      <td>B092BA29</td>\n      <td>2D5A3</td>\n      <td>28A7</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>24</td>\n      <td>900</td>\n      <td>797</td>\n      <td>797</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 245
    }
   ],
   "source": [
    "data = pd.read_csv('product-cat-dataset.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df.describe()\n",
    "\n",
    "# 15 level_1 classes # 39 level_2 classes # 43 level_3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0  gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19    D06E\n",
       "1  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "2  tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19    D06E\n",
       "3  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "4  easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6    98CF"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gerb cap help keep littl on head cov warm day ...</td>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>D06E</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>98CF</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tut ballet anym leap foxy fash ruffl tul toddl...</td>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>D06E</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>98CF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>easy keep feel warm cozy inf toddl girl hoody ...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>98CF</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 246
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1063, 3435, 3459, 7763, 7797, 7805, 7817, 7868, 7945, 7971, 7997, 8013]"
      ]
     },
     "metadata": {},
     "execution_count": 247
    }
   ],
   "source": [
    "# Check if data has missing values in the Description column\n",
    "# missing = df['Description'].isnull().index.tolist()\n",
    "\n",
    "missing_descriptions_indices = df[df['Description'].isnull()].index.tolist()\n",
    "missing_descriptions_indices\n",
    "#12 rows missing descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10637, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 248
    }
   ],
   "source": [
    "# Remove missing descriptions rows from dataframe\n",
    "# df.dropna()\n",
    "df = df[df['Description'].notna()]\n",
    "df.shape\n",
    "#shape is 10637 rows which is 12 less than original 10649 so know we have dropped the correct amount of rows from the dataframe"
   ]
  },
  {
   "source": [
    "## Create subset of data to workwith as dataset too large"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0                        trendy styl wom dress papil  AAC8EE56   914A1    D97D\n",
       "1  kenne col tak class peaco next level coat perf...  57164AC1   7B638    0F8B\n",
       "2  get set gym run outstand cas styl young men ta...  4513C920   31FED    215F\n",
       "3  busy cas hang favorit pair jean men wov window...  4513C920   F4055    7C00\n",
       "4  scoop metaph wom shirt loos fit comfort ess bu...  2CEC27F1   BAE8A    2ABA"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>trendy styl wom dress papil</td>\n      <td>AAC8EE56</td>\n      <td>914A1</td>\n      <td>D97D</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kenne col tak class peaco next level coat perf...</td>\n      <td>57164AC1</td>\n      <td>7B638</td>\n      <td>0F8B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>get set gym run outstand cas styl young men ta...</td>\n      <td>4513C920</td>\n      <td>31FED</td>\n      <td>215F</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>busy cas hang favorit pair jean men wov window...</td>\n      <td>4513C920</td>\n      <td>F4055</td>\n      <td>7C00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>scoop metaph wom shirt loos fit comfort ess bu...</td>\n      <td>2CEC27F1</td>\n      <td>BAE8A</td>\n      <td>2ABA</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 249
    }
   ],
   "source": [
    "df = df.sample(n = 8000)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Classes where the number of instances is < 10 (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AAC8EE56    691\n35E04739    684\nB092BA29    665\n57164AC1    646\n2CEC27F1    646\nEFEF723B    623\n69286F45    621\n09BF5150    583\n96F95EEC    438\n4C3D8686    430\n4513C920    429\n3E1E0D78    408\n014303D1    388\nD410C91A    379\n90A8B052    369\nName: Level_1, dtype: int64\nNumber of Unique Level 1 Categories:  15\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_1 \n",
    "print(df.Level_1.value_counts())\n",
    "print('Number of Unique Level 1 Categories: ', df.Level_1.nunique())\n",
    "# no classes have less that 10 instances\n",
    "# 15 total categories for Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2D5A3    621\nACD06    379\nC719A    352\nCB803    352\n9B69F    351\n390F1    342\n5A8AB    341\n914A1    340\nB2DB4    338\n74974    338\nBAE8A    333\n375FE    324\n94728    322\n9D9EE    316\nA04D3    313\nADAD6    313\n7B638    310\nC7E19    304\nF4055    286\n7AED7    218\n02FA0    206\n77F62    170\n36080    125\nE6162     92\n223B2     92\n5E038     87\nE69F5     76\n31FED     67\nD5531     65\nF824F     54\n262E7     48\n915D4     39\n6C6B1     26\nAF6B9     24\n08960     17\n0864A     13\n80D5B      4\nA6301      1\nC66C5      1\nName: Level_2, dtype: int64\nNumber of Unique Level 2 Categories:  36\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_2\n",
    "print(df.Level_2.value_counts())\n",
    "# 3 classes have less than 10 instances\n",
    "\n",
    "# use mask to remove rows with those 3 options\n",
    "# 80D5B      6\n",
    "# C66C5      1\n",
    "# A6301      1\n",
    "\n",
    "mask_2 = df.Level_2.value_counts()\n",
    "df = df[df['Level_2'].isin(mask_2.index[mask_2>9])]\n",
    "print('Number of Unique Level 2 Categories: ', df.Level_2.nunique())\n",
    "\n",
    "# df.shape, df.Level_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Unique Level 3 Categories:  38\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_3\n",
    "df.Level_3.value_counts()\n",
    "# two classes < 10\n",
    "# CF52      1\n",
    "# DE3D      1\n",
    "\n",
    "mask_3 = df.Level_3.value_counts()\n",
    "df = df[df['Level_3'].isin(mask_3.index[mask_3>9])]\n",
    "# df.shape, df.Level_3.value_counts()\n",
    "print('Number of Unique Level 3 Categories: ', df.Level_3.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's write a Function to Prepare Text (4 marks)\n",
    "We will apply it to our DataFrame later on\n",
    "\n",
    "* This function receives a text string and performs the following:\n",
    "* Convert text to lower case\n",
    "* Remove punctuation marks\n",
    "* Apply stemming using the popular Snowball or Porter Stemmer (optional)\n",
    "* Apply NGram Tokenisation\n",
    "* Return the tokenised text as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import re\n",
    "snowball_stemmer = SnowballStemmer(language='english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# def my_preprocessor(text):\n",
    "#     text=text.lower() #lowercase text (done be default if don't use a custom preprocessor)\n",
    "#     text=re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "#     text=re.sub(\"\\\\s+(in|the|all|for|and|on)\\\\s+\",\" _connector_ \",text) # normalize certain words\n",
    "    \n",
    "#     # stem words\n",
    "#     words=re.split(\"\\\\s+\",text)\n",
    "#     stemmed_words=[porter_stemmer.stem(word=word) for word in words]\n",
    "#     return ' '.join(stemmed_words)\n",
    "\n",
    "# def scrub_words(text):\n",
    "#     \"\"\"Basic cleaning of texts.\"\"\"\n",
    "    \n",
    "#     # remove html markup\n",
    "#     text=re.sub(\"(<.*?>)\",\"\",text)\n",
    "    \n",
    "#     #remove non-ascii and digits\n",
    "#     text=re.sub(\"(\\\\W|\\\\d)\",\" \",text)\n",
    "    \n",
    "#     #remove whitespace\n",
    "#     text=text.strip()\n",
    "#     return text\n",
    "\n",
    "def scrub_words(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[_]','', text)\n",
    "    return text\n",
    "\n",
    "def process_text(text, n = 3):\n",
    "    # 1. Convert text to lower case and remove all punctuation\n",
    "    scrubbed_text =scrub_words(text)                \n",
    "    \n",
    "    # 2. Tokenize words\n",
    "    token_words = word_tokenize(scrubbed_text)      \n",
    "\n",
    "    #3. Apply stemming\n",
    "    stem_words = [snowball_stemmer.stem(w) for w in token_words] \n",
    "    \n",
    "    # 4. Apply Ngram Tokenisation\n",
    "    n_grams = ngrams(stem_words, n)                 \n",
    "    return [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "def process_text2(text):\n",
    "    # 1. Convert text to lower case and remove all punctuation\n",
    "    scrubbed_text =scrub_words(text)                \n",
    "    \n",
    "    # 2. Tokenize words\n",
    "    token_words = word_tokenize(scrubbed_text)      \n",
    "\n",
    "    #3. Apply stemming\n",
    "    stem_words = [snowball_stemmer.stem(w) for w in token_words] \n",
    "    \n",
    "    # 4. Apply Ngram Tokenisation\n",
    "    return ' '.join(stem_words)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'here were test the processtext function result are as follow'"
      ]
     },
     "metadata": {},
     "execution_count": 254
    }
   ],
   "source": [
    "# Here is an example function call\n",
    "process_text(\"Here we're testing the process_text function, results are as follows:\")\n",
    "process_text2(\"Here we're testing the process_text function, results are as follows:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's apply TF-IDF to extract features from plain text (10 marks)\n",
    "### Might take a while...\n",
    "### Here you apply the process_text function to the Description column of the data\n",
    "### Then you pass the results to the bag of words tranformer\n",
    "### See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df['bow'] = df['Description'].apply(lambda x: process_text(x, 3))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import chain"
   ]
  },
  {
   "source": [
    "## Use Count Vectorizer to get Bag of Words with ngram of 3 words "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# descriptions = df['Description'].values\n",
    "\n",
    "# cv = CountVectorizer(preprocessor=process_text2, ngram_range=(3,3), max_features=15000)\n",
    "# X = cv.fit_transform(descriptions)\n",
    "# count_vector = cv.transform(descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4986, 15000)"
      ]
     },
     "metadata": {},
     "execution_count": 258
    }
   ],
   "source": [
    "X.shape # => 10627, 10000 \n",
    "#10,627 documenst and vocab of 10,000\n",
    "count_vector.shape\n"
   ]
  },
  {
   "source": [
    "## Calculate TFIDF Scores and add to DF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_transformer = TfidfTransformer()  \n",
    "# tfidf_transformer.fit(X)\n",
    "\n",
    "# df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(), columns=['idf_weights'])\n",
    "# df_idf.sort_values(by=['idf_weights'], ascending=False)\n",
    "\n",
    "# #compute tfidf scores\n",
    "# tf_idf_vector = tfidf_transformer.transform(count_vector)\n",
    "# feature_names = cv.get_feature_names()\n",
    "\n",
    "# #get tfidf vector for fist doc\n",
    "# first_descrip_vector = tf_idf_vector[0]\n",
    "\n",
    "# #print the scores for first description\n",
    "# tfidf_df_one = pd.DataFrame(first_descrip_vector.T.todense(), index=feature_names, columns=['tfidf'])\n",
    "# tfidf_df_one.sort_values(by=['tfidf'],ascending=False)\n",
    "\n",
    "# #print scores for all descriptions\n",
    "# tfidf_df = pd.DataFrame(tf_idf_vector.todense(), columns=feature_names)\n",
    "# tfidf_df.head()\n",
    "# tfidf_df.shape\n",
    "# #10,000 vocabs columns / 10627 descriptions rows\n"
   ]
  },
  {
   "source": [
    "## Use TFIDF Vectorizer to do same thing as combining Count Vectorizer and TFIDF Transformer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7993, 15000)"
      ]
     },
     "metadata": {},
     "execution_count": 260
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(3,3), preprocessor=process_text2, max_features=15000)\n",
    "X = vectorizer.fit_transform(df['Description'].values)\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n",
    "# tfidf_df.head()\n",
    "tfidf_df.shape"
   ]
  },
  {
   "source": [
    "## Check to see if they are the same"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_df_one = pd.DataFrame(first_descrip_vector.T.todense(), index=feature_names, columns=['tfidf'])\n",
    "# # print(tfidf_df_one.sort_values(by=['tfidf'],ascending=False))\n",
    "\n",
    "# tfidf_df2_one = pd.DataFrame(X2[0].T.todense(), index=feature_names, columns=['tfidf'])\n",
    "# # print(tfidf_df2_one.sort_values(by=['tfidf'],ascending=False))\n",
    "\n",
    "\n",
    "# if ((tfidf_df_one.values == tfidf_df2_one.values).all()):\n",
    "#     print('Arrays are equal showing tfidf vectorizer returns same result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use `.transform` on our Bag-of-Words (bow) transformed object and transform the entire DataFrame of text file contents. Let's go ahead and check out how the bag-of-words counts for the entire corpus in a large, sparse matrix:\n",
    "\n",
    "After that you pass the result of the previous step to sklearn's TfidfTransformer  \n",
    "which will convert them into a feature matrix  \n",
    "See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "\n",
    "The resulting matrix is in sparse format, we can transform it into dense  \n",
    "Code prepared for you so you can see what results look like\n",
    "\n",
    "This is an example result, the matrix will contain lots of zero values, that is expected.  \n",
    "Some values will be non-zero\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   00 24 waist  00 ct tgw  000 first print  000 photo 10  \\\n",
       "0          0.0        0.0              0.0           0.0   \n",
       "1          0.0        0.0              0.0           0.0   \n",
       "2          0.0        0.0              0.0           0.0   \n",
       "3          0.0        0.0              0.0           0.0   \n",
       "4          0.0        0.0              0.0           0.0   \n",
       "\n",
       "   01number pag 192bind  01number pag bind  02 05number pag  03 01number pag  \\\n",
       "0                   0.0                0.0              0.0              0.0   \n",
       "1                   0.0                0.0              0.0              0.0   \n",
       "2                   0.0                0.0              0.0              0.0   \n",
       "3                   0.0                0.0              0.0              0.0   \n",
       "4                   0.0                0.0              0.0              0.0   \n",
       "\n",
       "   04 01number pag  05 01number pag  ...  zip pocket two  zip princess seam  \\\n",
       "0              0.0              0.0  ...             0.0                0.0   \n",
       "1              0.0              0.0  ...             0.0                0.0   \n",
       "2              0.0              0.0  ...             0.0                0.0   \n",
       "3              0.0              0.0  ...             0.0                0.0   \n",
       "4              0.0              0.0  ...             0.0                0.0   \n",
       "\n",
       "   zip real fur  zip sid pocket  zip stash pocket  zip two front  \\\n",
       "0           0.0             0.0               0.0            0.0   \n",
       "1           0.0             0.0               0.0            0.0   \n",
       "2           0.0             0.0               0.0            0.0   \n",
       "3           0.0             0.0               0.0            0.0   \n",
       "4           0.0             0.0               0.0            0.0   \n",
       "\n",
       "   zon afric also  zon ant col  zon babi us  zon provid gre  \n",
       "0             0.0          0.0          0.0             0.0  \n",
       "1             0.0          0.0          0.0             0.0  \n",
       "2             0.0          0.0          0.0             0.0  \n",
       "3             0.0          0.0          0.0             0.0  \n",
       "4             0.0          0.0          0.0             0.0  \n",
       "\n",
       "[5 rows x 15000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00 24 waist</th>\n      <th>00 ct tgw</th>\n      <th>000 first print</th>\n      <th>000 photo 10</th>\n      <th>01number pag 192bind</th>\n      <th>01number pag bind</th>\n      <th>02 05number pag</th>\n      <th>03 01number pag</th>\n      <th>04 01number pag</th>\n      <th>05 01number pag</th>\n      <th>...</th>\n      <th>zip pocket two</th>\n      <th>zip princess seam</th>\n      <th>zip real fur</th>\n      <th>zip sid pocket</th>\n      <th>zip stash pocket</th>\n      <th>zip two front</th>\n      <th>zon afric also</th>\n      <th>zon ant col</th>\n      <th>zon babi us</th>\n      <th>zon provid gre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 15000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 262
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now the Data is Ready for Classifier Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train and Test sets (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dfs\n",
    "# === not sure if actually need to do this ===\n",
    "tfidf_df.reset_index(inplace=True, drop=True)\n",
    "# tfidf_df.head()\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "data = pd.concat([df, tfidf_df], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=1811)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 4:]\n",
    "y_train = train.iloc[:, 0: 4]\n",
    "X_test = test.iloc[:, 4:]\n",
    "y_test = test.iloc[:, 0: 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to reset index in each dataframe (depends on you how you do things)\n",
    "# done for you to make it clearer\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need to take classes as separate columns (depends on you how you do things)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "class1_train = y_train['Level_1'].astype(str)\n",
    "class1_test = y_test['Level_1'].astype(str)\n",
    "\n",
    "class2_train = y_train['Level_2'].astype(str)\n",
    "class2_test = y_test['Level_2'].astype(str)\n",
    "\n",
    "class3_train = y_train['Level_3'].astype(str)\n",
    "class3_test = y_test['Level_3'].astype(str)\n",
    "\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# X_train_min_max = min_max_scaler.fit_transform(X_train)\n",
    "# X_test_min_max = min_max_scaler.fit_transform(X_test)\n",
    "\n",
    "# y_train[y_train['Level_1'].isnull()].index.tolist()\n",
    "# \n",
    "# missing_descriptions_indices = df[df['Description'].isnull()].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3988,)"
      ]
     },
     "metadata": {},
     "execution_count": 223
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for the three levels (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy:  0.7035647279549718\n"
     ]
    }
   ],
   "source": [
    "# Create and save model for level 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# print(X_train.head())\n",
    "# print(class1_train.head())\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('accuracy: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.6735459662288931\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('Accuracy: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.6816760475297061\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier().fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('Accuracy: ', score)\n",
    "\n",
    "with open('level1.pk', 'wb') as cls:\n",
    "    pickle.dump(classifier, cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Create and save models for level 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 1 Category:  EFEF723B\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  EFEF723B  SCORE:  0.7933884297520661\n",
      "Level 1 Category:  96F95EEC\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  96F95EEC  SCORE:  0.8588235294117647\n",
      "Level 1 Category:  2CEC27F1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  2CEC27F1  SCORE:  0.8823529411764706\n",
      "Level 1 Category:  09BF5150\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  09BF5150  SCORE:  0.7461538461538462\n",
      "Level 1 Category:  B092BA29\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  B092BA29  SCORE:  0.6030534351145038\n",
      "Level 1 Category:  AAC8EE56\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  AAC8EE56  SCORE:  0.7482993197278912\n",
      "Level 1 Category:  35E04739\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  35E04739  SCORE:  0.6666666666666666\n",
      "Level 1 Category:  4513C920\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  4513C920  SCORE:  0.8266666666666667\n",
      "Level 1 Category:  69286F45\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 2D5A3  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 1 Category:  4C3D8686\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  4C3D8686  SCORE:  0.7878787878787878\n",
      "Level 1 Category:  3E1E0D78\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  3E1E0D78  SCORE:  0.8656716417910447\n",
      "Level 1 Category:  57164AC1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  57164AC1  SCORE:  0.7478991596638656\n",
      "Level 1 Category:  90A8B052\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  90A8B052  SCORE:  0.9873417721518988\n",
      "Level 1 Category:  014303D1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  014303D1  SCORE:  0.8390804597701149\n",
      "Level 1 Category:  D410C91A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: ACD06  SO SKIP MODEL CREATION \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['69286F45', '2D5A3'], ['D410C91A', 'ACD06']]"
      ]
     },
     "metadata": {},
     "execution_count": 312
    }
   ],
   "source": [
    "# in this space you will be fitting models for the level 2 data \n",
    "#so you will want to split the test data into sub data for each classification e.g.\n",
    "\n",
    "#get unique level 1 categories\n",
    "level1cats = class1_train.unique()\n",
    "\n",
    "lvl1_cat_indexes = []\n",
    "lvl1_cat_indexes_test = []\n",
    "lvl1_unique = []\n",
    "\n",
    "for index, cat in enumerate(level1cats): \n",
    "    print('Level 1 Category: ', cat)\n",
    "    #get indexes for train data and test data\n",
    "    a = list(class1_train[class1_train == cat].index)\n",
    "    b = list(class1_test[class1_test == cat].index)\n",
    "    lvl1_cat_indexes.append(a)\n",
    "    lvl1_cat_indexes_test.append(b)\n",
    "\n",
    "    # some class 2 data only has one unique value for a particular level 1 category so can't create a model\n",
    "    if class2_train.loc[a].nunique() == 1:\n",
    "        unique_val = class2_train.loc[a].unique()[0]\n",
    "        print('ERROR: ONLY ONE UNIQUE VALUE:', unique_val, ' SO SKIP MODEL CREATION \\n')\n",
    "        #put values into array for prediction later\n",
    "        lvl1_unique.append([cat, unique_val])\n",
    "        continue\n",
    "    #create model with train data for unique level 1 category\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train.loc[a], class2_train[a])\n",
    "\n",
    "    score = classifier.score(X_test.loc[b], class2_test[b])\n",
    "    print('\\n Accuracy score for LVL 1 CAT: ', cat, ' SCORE: ', score)\n",
    "\n",
    "    #save model\n",
    "    model_name = 'level2_' + cat + '.pk'\n",
    "    with open(model_name, 'wb') as cls: \n",
    "        pickle.dump(classifier, cls)\n",
    "    # limit = 5\n",
    "    # if index == limit: \n",
    "    #     break\n",
    "\n",
    "# cat 69286F45 unique val 2D5A3\n",
    "# D410C91A => ACD06\n",
    "lvl1_unique"
   ]
  },
  {
   "source": [
    "## Create and save models for level 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 2 Category:  CB803\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 627D  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  36080\n",
      "ERROR: ONLY ONE UNIQUE VALUE: C563  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  ADAD6\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 98CF  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  915D4\n",
      "ERROR: ONLY ONE UNIQUE VALUE: A2FA  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  5A8AB\n",
      "ERROR: ONLY ONE UNIQUE VALUE: AA6B  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  375FE\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 1F61  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  914A1\n",
      "ERROR: ONLY ONE UNIQUE VALUE: D97D  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  390F1\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6856  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  F4055\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  F4055  SCORE:  0.5714285714285714\n",
      "Level 2 Category:  2D5A3\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 28A7  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  A04D3\n",
      "ERROR: ONLY ONE UNIQUE VALUE: C5B4  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  223B2\n",
      "ERROR: ONLY ONE UNIQUE VALUE: F213  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  74974\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 62E8  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  9D9EE\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 05A0  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  7B638\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 0F8B  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  08960\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 1000  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  9B69F\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 80C4  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  7AED7\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6539  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  BAE8A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 2ABA  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  B2DB4\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 21DA  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  ACD06\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 33D1  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  77F62\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 5AE1  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  94728\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 5912  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  C7E19\n",
      "ERROR: ONLY ONE UNIQUE VALUE: D06E  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  E69F5\n",
      "ERROR: ONLY ONE UNIQUE VALUE: DDD5  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  C719A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: A0E2  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  5E038\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6BE5  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  02FA0\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 078B  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  262E7\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 29B3  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  31FED\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  31FED  SCORE:  0.2\n",
      "Level 2 Category:  E6162\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 2E14  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  F824F\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 7288  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  AF6B9\n",
      "ERROR: ONLY ONE UNIQUE VALUE: A104  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  6C6B1\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 3AAD  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  D5531\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6253  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  0864A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 96B8  SO SKIP MODEL CREATION \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(34, 36)"
      ]
     },
     "metadata": {},
     "execution_count": 296
    }
   ],
   "source": [
    "# get unique level 2 categories\n",
    "level2cats = class2_train.unique()\n",
    "\n",
    "lvl2_cat_indexes = []\n",
    "lvl2_cat_indexes_test = []\n",
    "lvl2_unique = []\n",
    "for index, cat in enumerate(level2cats): \n",
    "    print('Level 2 Category: ', cat)\n",
    "    #get indexes for train data and test data\n",
    "    a = list(class2_train[class2_train == cat].index)\n",
    "    b = list(class2_test[class2_test == cat].index)\n",
    "\n",
    "    lvl2_cat_indexes.append(a)\n",
    "    lvl2_cat_indexes_test.append(b)\n",
    "\n",
    "    # some class 2 data only has one unique value for a particular level 1 category so can't create a model\n",
    "    if class3_train.loc[a].nunique() == 1:\n",
    "        unique_val = class3_train.loc[a].unique()[0]\n",
    "        print('ERROR: ONLY ONE UNIQUE VALUE:', unique_val, ' SO SKIP MODEL CREATION \\n')\n",
    "        #put values into array for prediction later\n",
    "        lvl2_unique.append([cat, unique_val])\n",
    "        continue\n",
    "    #create model with train data for unique level 2 category\n",
    "    classifier = SGDClassifier()\n",
    "    classifier.fit(X_train.loc[a], class3_train[a])\n",
    "    score = classifier.score(X_test.loc[b], class3_test[b])\n",
    "    print('\\n Accuracy score for LVL 2 CAT: ', cat, ' SCORE: ', score)\n",
    "\n",
    "    #save model\n",
    "    model_name = 'level3_' + cat + '.pk'\n",
    "    with open(model_name, 'wb') as cls: \n",
    "        pickle.dump(classifier, cls)\n",
    "    # limit = 2\n",
    "    # if index == limit: \n",
    "    #     break\n",
    "\n",
    "len(lvl2_unique), len(level2cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Level1_Pred Level2_Pred Level3_Pred\n",
       "0    EFEF723B         NaN         NaN\n",
       "1    35E04739         NaN         NaN\n",
       "2    4C3D8686         NaN         NaN\n",
       "3    35E04739         NaN         NaN\n",
       "4    AAC8EE56         NaN         NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Level1_Pred</th>\n      <th>Level2_Pred</th>\n      <th>Level3_Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EFEF723B</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4C3D8686</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAC8EE56</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 299
    }
   ],
   "source": [
    "# Creating an empty Dataframe with column names only (depends on you how you do things)\n",
    "results = pd.DataFrame(columns=['Level1_Pred', 'Level2_Pred', 'Level3_Pred'])\n",
    "\n",
    "## Here we reload the saved models and use them to predict the levels\n",
    "# load model for level 1 (done for you)\n",
    "with open('level1.pk', 'rb') as nb:\n",
    "    model = pickle.load(nb)\n",
    "\n",
    "## loop through the test data, predict level 1, then based on that predict level 2\n",
    "## and based on level 2 predict level 3 (you need to load saved models accordingly)\n",
    "level1_pred = model.predict(X_test)\n",
    "results['Level1_Pred'] = level1_pred\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['69286F45', '2D5A3'], ['D410C91A', 'ACD06']]\n",
      "['69286F45', '2D5A3', 'D410C91A', 'ACD06']\n",
      "Level 1 Category:  EFEF723B\n",
      "Level 1 Category:  96F95EEC\n",
      "Level 1 Category:  2CEC27F1\n",
      "Level 1 Category:  09BF5150\n",
      "Level 1 Category:  B092BA29\n",
      "Level 1 Category:  AAC8EE56\n",
      "Level 1 Category:  35E04739\n",
      "Level 1 Category:  4513C920\n",
      "Level 1 Category:  69286F45\n",
      "found cat in unique\n",
      "Level 1 Category:  4C3D8686\n",
      "Level 1 Category:  3E1E0D78\n",
      "Level 1 Category:  57164AC1\n",
      "Level 1 Category:  90A8B052\n",
      "Level 1 Category:  014303D1\n",
      "Level 1 Category:  D410C91A\n",
      "found cat in unique\n"
     ]
    }
   ],
   "source": [
    "# for each category in level 1 predictions => use that plus the model for that category to predict level 2\n",
    "\n",
    "flat_lvl1_unique = [element for sublist in lvl1_unique for element in sublist]\n",
    "print(flat_lvl1_unique)\n",
    "for index, cat in enumerate(level1cats): \n",
    "    print('Level 1 Category: ', cat)\n",
    "    # get indexes\n",
    "    a = list(results[results['Level1_Pred']== cat].index)\n",
    "    # if cat is in the arrayof lvl1_unique => set predicted values to its pair\n",
    "    if cat in flat_lvl1_unique:\n",
    "        index = flat_lvl1_unique.index(cat)\n",
    "        predicted = flat_lvl1_unique[index+1]\n",
    "        print('Unique Category - no model')\n",
    "        results['Level2_Pred'].loc[a] =  predicted\n",
    "        continue\n",
    "    # get model\n",
    "    model_name = 'level2_' + cat + '.pk'\n",
    "    with open(model_name, 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "    results['Level2_Pred'].loc[a] =  model.predict(X_test.loc[a])\n",
    "    # print(model.predict(X_test.loc[a]))\n",
    "    # limit = 2\n",
    "    # if index == limit: \n",
    "    #     break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 2 Category:  CB803\n",
      "Unique Category - no model\n",
      "Level 2 Category:  36080\n",
      "Unique Category - no model\n",
      "Level 2 Category:  ADAD6\n",
      "Unique Category - no model\n",
      "Level 2 Category:  915D4\n",
      "Unique Category - no model\n",
      "Level 2 Category:  5A8AB\n",
      "Unique Category - no model\n",
      "Level 2 Category:  375FE\n",
      "Unique Category - no model\n",
      "Level 2 Category:  914A1\n",
      "Unique Category - no model\n",
      "Level 2 Category:  390F1\n",
      "Unique Category - no model\n",
      "Level 2 Category:  F4055\n",
      "Level 2 Category:  2D5A3\n",
      "Unique Category - no model\n",
      "Level 2 Category:  A04D3\n",
      "Unique Category - no model\n",
      "Level 2 Category:  223B2\n",
      "Unique Category - no model\n",
      "Level 2 Category:  74974\n",
      "Unique Category - no model\n",
      "Level 2 Category:  9D9EE\n",
      "Unique Category - no model\n",
      "Level 2 Category:  7B638\n",
      "Unique Category - no model\n",
      "Level 2 Category:  08960\n",
      "Unique Category - no model\n",
      "Level 2 Category:  9B69F\n",
      "Unique Category - no model\n",
      "Level 2 Category:  7AED7\n",
      "Unique Category - no model\n",
      "Level 2 Category:  BAE8A\n",
      "Unique Category - no model\n",
      "Level 2 Category:  B2DB4\n",
      "Unique Category - no model\n",
      "Level 2 Category:  ACD06\n",
      "Unique Category - no model\n",
      "Level 2 Category:  77F62\n",
      "Unique Category - no model\n",
      "Level 2 Category:  94728\n",
      "Unique Category - no model\n",
      "Level 2 Category:  C7E19\n",
      "Unique Category - no model\n",
      "Level 2 Category:  E69F5\n",
      "Unique Category - no model\n",
      "Level 2 Category:  C719A\n",
      "Unique Category - no model\n",
      "Level 2 Category:  5E038\n",
      "Unique Category - no model\n",
      "Level 2 Category:  02FA0\n",
      "Unique Category - no model\n",
      "Level 2 Category:  262E7\n",
      "Unique Category - no model\n",
      "Level 2 Category:  31FED\n",
      "Level 2 Category:  E6162\n",
      "Unique Category - no model\n",
      "Level 2 Category:  F824F\n",
      "Unique Category - no model\n",
      "Level 2 Category:  AF6B9\n",
      "Unique Category - no model\n",
      "Level 2 Category:  6C6B1\n",
      "Unique Category - no model\n",
      "Level 2 Category:  D5531\n",
      "Unique Category - no model\n",
      "Level 2 Category:  0864A\n",
      "Unique Category - no model\n"
     ]
    }
   ],
   "source": [
    "# for each category in level 1 predictions => use that plus the model for that category to predict level 2\n",
    "\n",
    "flat_lvl2_unique = [element for sublist in lvl2_unique for element in sublist]\n",
    "# print(flat_lvl1_unique)\n",
    "for index, cat in enumerate(level2cats): \n",
    "    print('Level 2 Category: ', cat)\n",
    "    # get indexes\n",
    "    a = list(results[results['Level2_Pred']== cat].index)\n",
    "    # if cat is in the arrayof lvl1_unique => set predicted values to its pair\n",
    "    if cat in flat_lvl2_unique:\n",
    "        index = flat_lvl2_unique.index(cat)\n",
    "        predicted = flat_lvl2_unique[index+1]\n",
    "        print('Unique Category - no model')\n",
    "        results['Level3_Pred'].loc[a] =  predicted\n",
    "        continue\n",
    "    # get model\n",
    "    model_name = 'level3_' + cat + '.pk'\n",
    "    with open(model_name, 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "    results['Level3_Pred'].loc[a] =  model.predict(X_test.loc[a])\n",
    "    # print(model.predict(X_test.loc[a]))\n",
    "    # limit = 2\n",
    "    # if index == limit: \n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results['Level3_Pred'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Level1_Pred Level2_Pred Level3_Pred\n",
       "0       EFEF723B         NaN         NaN\n",
       "1       35E04739         NaN         NaN\n",
       "2       4C3D8686         NaN         NaN\n",
       "3       35E04739         NaN         NaN\n",
       "4       AAC8EE56         NaN         NaN\n",
       "...          ...         ...         ...\n",
       "1594    35E04739         NaN         NaN\n",
       "1595    57164AC1         NaN         NaN\n",
       "1596    35E04739         NaN         NaN\n",
       "1597    35E04739         NaN         NaN\n",
       "1598    AAC8EE56         NaN         NaN\n",
       "\n",
       "[1599 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Level1_Pred</th>\n      <th>Level2_Pred</th>\n      <th>Level3_Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EFEF723B</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4C3D8686</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AAC8EE56</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>57164AC1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>AAC8EE56</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1599 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 283
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Level1_Pred</th>\n",
       "      <th>Level2_Pred</th>\n",
       "      <th>Level3_Pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>BAE8A</td>\n",
       "      <td>2ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2CEC27F1</td>\n",
       "      <td>BAE8A</td>\n",
       "      <td>2ABA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09BF5150</td>\n",
       "      <td>C7E19</td>\n",
       "      <td>D06E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4513C920</td>\n",
       "      <td>F4055</td>\n",
       "      <td>7C00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4513C920</td>\n",
       "      <td>F4055</td>\n",
       "      <td>7C00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>09BF5150</td>\n",
       "      <td>262E7</td>\n",
       "      <td>29B3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>69286F45</td>\n",
       "      <td>2D5A3</td>\n",
       "      <td>28A7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>3E1E0D78</td>\n",
       "      <td>9D9EE</td>\n",
       "      <td>05A0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>57164AC1</td>\n",
       "      <td>7B638</td>\n",
       "      <td>0F8B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>90A8B052</td>\n",
       "      <td>C719A</td>\n",
       "      <td>A0E2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Level1_Pred Level2_Pred Level3_Pred\n",
       "0       2CEC27F1       BAE8A        2ABA\n",
       "1       2CEC27F1       BAE8A        2ABA\n",
       "2       09BF5150       C7E19        D06E\n",
       "3       4513C920       F4055        7C00\n",
       "4       4513C920       F4055        7C00\n",
       "...          ...         ...         ...\n",
       "2121    09BF5150       262E7        29B3\n",
       "2122    69286F45       2D5A3        28A7\n",
       "2123    3E1E0D78       9D9EE        05A0\n",
       "2124    57164AC1       7B638        0F8B\n",
       "2125    90A8B052       C719A        A0E2\n",
       "\n",
       "[2126 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## After you add the predictions to the results dataframe\n",
    "## they should look like this\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on each level (4 marks)\n",
    "Now you have the predictions for each level (in the test data), and you also have the actual levels, you can compute the accurcay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f4c3f951145d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Level 1 accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LEVEL 1 ACCURACY: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Level_1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel1_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Level 1 accuracy\n",
    "print('LEVEL 1 ACCURACY: ', accuracy_score(y_test['Level_1'], level1_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 2 accuracy\n",
    "print('LEVEL 2 ACCURACY: ', accuracy_score(y_test['Level_2'], results['Level2_Pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 3 accuracy\n",
    "print('LEVEL 3 ACCURACY: ', accuracy_score(y_test['Level_3'], results['Level3_Pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python391jvsc74a57bd0ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963",
   "display_name": "Python 3.9.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "metadata": {
   "interpreter": {
    "hash": "ac59ebe37160ed0dfa835113d9b8498d9f09ceb179beaac4002f036b9467c963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}