{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Work - Statistics and Statistics Mining\n",
    "## Patrick O'Neill\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore the data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Description   Level_1 Level_2  \\\n",
       "count                                               10627     10639   10639   \n",
       "unique                                               9668        15      36   \n",
       "top     glory gorg col fing complet outfit express moo...  B092BA29   2D5A3   \n",
       "freq                                                   24       900     797   \n",
       "\n",
       "       Level_3  \n",
       "count    10639  \n",
       "unique      94  \n",
       "top       28A7  \n",
       "freq       332  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10627</td>\n      <td>10639</td>\n      <td>10639</td>\n      <td>10639</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>9668</td>\n      <td>15</td>\n      <td>36</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>glory gorg col fing complet outfit express moo...</td>\n      <td>B092BA29</td>\n      <td>2D5A3</td>\n      <td>28A7</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>24</td>\n      <td>900</td>\n      <td>797</td>\n      <td>332</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "data = pd.read_csv('product-category-dataset-improved.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df.describe()\n",
    "\n",
    "# 15 level_1 classes # 36 level_2 classes #94 level_3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0  gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19    FDCF\n",
       "1  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    ED0D\n",
       "2  tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19    D06E\n",
       "3  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "4  easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6    3918"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gerb cap help keep littl on head cov warm day ...</td>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>FDCF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>ED0D</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tut ballet anym leap foxy fash ruffl tul toddl...</td>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>D06E</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>98CF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>easy keep feel warm cozy inf toddl girl hoody ...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>3918</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 12 missing indices\n"
     ]
    }
   ],
   "source": [
    "# Check if data has missing values in the Description column\n",
    "\n",
    "missing_descriptions_indices = df[df['Description'].isnull()].index.tolist()\n",
    "\n",
    "print('There are', len(missing_descriptions_indices), 'missing indices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10627, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Remove missing descriptions rows from dataframe\n",
    "df = df[df['Description'].notna()]\n",
    "df.shape\n"
   ]
  },
  {
   "source": [
    "Shape is 10627 rows which is 12 less than original 10639 so know we have dropped the correct amount of rows from the dataframe\n",
    "\n",
    "## Create subset of data to workwith as dataset too large"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8500, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0  sweet park bask sunshin princess picn girl whi...  AAC8EE56   914A1    F72B\n",
       "1  styl jean comfy pj soft gen stretchable cut br...  EFEF723B   CB803    2C15\n",
       "2  styl littl girl sur ad 17 piec toddl girl hair...  09BF5150   C7E19    FDCF\n",
       "3  vert seam sculpt suppl leath scub jacket acc t...  57164AC1   94728    5912\n",
       "4  find man ped target com revlon nail enamel del...  D410C91A   ACD06    33D1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>sweet park bask sunshin princess picn girl whi...</td>\n      <td>AAC8EE56</td>\n      <td>914A1</td>\n      <td>F72B</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>styl jean comfy pj soft gen stretchable cut br...</td>\n      <td>EFEF723B</td>\n      <td>CB803</td>\n      <td>2C15</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>styl littl girl sur ad 17 piec toddl girl hair...</td>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>FDCF</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vert seam sculpt suppl leath scub jacket acc t...</td>\n      <td>57164AC1</td>\n      <td>94728</td>\n      <td>5912</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>find man ped target com revlon nail enamel del...</td>\n      <td>D410C91A</td>\n      <td>ACD06</td>\n      <td>33D1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# take sample of 8500 of total count to reduce computational load for the classifiers\n",
    "\n",
    "df = df.sample(n = 8500)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# check shape to make sure correct transformation\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Classes where the number of instances is < 10 (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "B092BA29    713\n57164AC1    704\n35E04739    702\nAAC8EE56    698\n2CEC27F1    674\n09BF5150    646\nEFEF723B    645\n69286F45    632\n96F95EEC    482\n4C3D8686    480\n3E1E0D78    453\n4513C920    449\nD410C91A    415\n014303D1    406\n90A8B052    401\nName: Level_1, dtype: int64\nNumber of Unique Level 1 Categories:  15\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_1 \n",
    "print(df.Level_1.value_counts())\n",
    "print('Number of Unique Level 1 Categories: ', df.Level_1.nunique())\n",
    "# No classes have less than 10 instances"
   ]
  },
  {
   "source": [
    "There are 15 level 1 classes all of which have more than 10 instances. \n",
    "No classes will be dropped from level 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Unique Level 2 Categories:  36\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2D5A3    632\n",
       "ACD06    415\n",
       "C719A    381\n",
       "74974    378\n",
       "9D9EE    371\n",
       "B2DB4    365\n",
       "9B69F    362\n",
       "5A8AB    359\n",
       "375FE    354\n",
       "94728    353\n",
       "CB803    353\n",
       "C7E19    350\n",
       "BAE8A    349\n",
       "A04D3    341\n",
       "7B638    338\n",
       "390F1    337\n",
       "914A1    336\n",
       "ADAD6    325\n",
       "F4055    290\n",
       "7AED7    219\n",
       "02FA0    219\n",
       "77F62    187\n",
       "36080    141\n",
       "223B2    102\n",
       "E69F5     91\n",
       "5E038     89\n",
       "E6162     82\n",
       "D5531     73\n",
       "31FED     68\n",
       "F824F     55\n",
       "262E7     52\n",
       "915D4     39\n",
       "AF6B9     33\n",
       "6C6B1     28\n",
       "08960     20\n",
       "0864A     13\n",
       "Name: Level_2, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Apply to Level_2\n",
    "\n",
    "# create mask based on value counts\n",
    "mask_2 = df.Level_2.value_counts()\n",
    "# apply mask to dataset\n",
    "df = df[df['Level_2'].isin(mask_2.index[mask_2>9])]\n",
    "print('Number of Unique Level 2 Categories: ', df.Level_2.nunique())\n",
    "\n",
    "#confirm no classes left have fewer than 10 instances\n",
    "df.Level_2.value_counts()"
   ]
  },
  {
   "source": [
    "All remaining level 2 classes have more than 10 instances."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Unique Level 3 Categories:  94\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "28A7    251\n",
       "2CFE    185\n",
       "33D1    184\n",
       "BB6B    182\n",
       "62E8    181\n",
       "       ... \n",
       "98A8     25\n",
       "1000     20\n",
       "74C9     16\n",
       "D55B     16\n",
       "96B8     13\n",
       "Name: Level_3, Length: 94, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Apply to Level_3\n",
    "\n",
    "#create mask \n",
    "mask_3 = df.Level_3.value_counts()\n",
    "#apply mask\n",
    "df = df[df['Level_3'].isin(mask_3.index[mask_3>9])]\n",
    "\n",
    "print('Number of Unique Level 3 Categories: ', df.Level_3.nunique())\n",
    "\n",
    "# check value counts all above 10 instances\n",
    "df.Level_3.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All remaining level 3 classes have more than 10 instances.\n",
    "\n",
    "### Now let's write a Function to Prepare Text (4 marks)\n",
    "We will apply it to our DataFrame later on\n",
    "\n",
    "* This function receives a text string and performs the following:\n",
    "* Convert text to lower case\n",
    "* Remove punctuation marks\n",
    "* Apply stemming using the popular Snowball or Porter Stemmer (optional)\n",
    "* Apply NGram Tokenisation\n",
    "* Return the tokenised text as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\hugho\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import re\n",
    "snowball_stemmer = SnowballStemmer(language='english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def scrub_words(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[_]','', text)\n",
    "    return text\n",
    "\n",
    "def process_text(text):\n",
    "    # 1. Convert text to lower case and remove all punctuation\n",
    "    scrubbed_text =scrub_words(text)                \n",
    "    \n",
    "    # 2. Tokenize words\n",
    "    token_words = word_tokenize(scrubbed_text)      \n",
    "\n",
    "    #3. Apply stemming\n",
    "    stem_words = [snowball_stemmer.stem(w) for w in token_words] \n",
    "    \n",
    "    # 4. Apply Ngram Tokenisation\n",
    "    return ' '.join(stem_words)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'here were test the processtext function result are as follow'"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Here is an example function call\n",
    "\n",
    "process_text(\"Here we're testing the process_text function, results are as follows:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply TF-IDF to extract features from plain text (10 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import chain"
   ]
  },
  {
   "source": [
    "## Use TFIDF Vectorizer which combines the process of using Count Vectorizer followed and TFIDF Transformer into one Process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(3,3), preprocessor=process_text, max_features=15000)\n",
    "\n",
    "X = vectorizer.fit_transform(df['Description'].values)\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8500, 15000)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   00 ct tgw  000 first print  000 photo 10  01number pag 192bind  \\\n",
       "0        0.0              0.0           0.0                   0.0   \n",
       "1        0.0              0.0           0.0                   0.0   \n",
       "2        0.0              0.0           0.0                   0.0   \n",
       "3        0.0              0.0           0.0                   0.0   \n",
       "4        0.0              0.0           0.0                   0.0   \n",
       "\n",
       "   01number pag bind  03 01number pag  03 15number pag  03 20number pag  \\\n",
       "0                0.0              0.0              0.0              0.0   \n",
       "1                0.0              0.0              0.0              0.0   \n",
       "2                0.0              0.0              0.0              0.0   \n",
       "3                0.0              0.0              0.0              0.0   \n",
       "4                0.0              0.0              0.0              0.0   \n",
       "\n",
       "   04 01number pag  04 03number pag  ...  zip princess seam  zip pullov part  \\\n",
       "0              0.0              0.0  ...                0.0              0.0   \n",
       "1              0.0              0.0  ...                0.0              0.0   \n",
       "2              0.0              0.0  ...                0.0              0.0   \n",
       "3              0.0              0.0  ...                0.0              0.0   \n",
       "4              0.0              0.0  ...                0.0              0.0   \n",
       "\n",
       "   zip sid pocket  zip slid comfort  zip stash pocket  zip two front  \\\n",
       "0             0.0               0.0               0.0            0.0   \n",
       "1             0.0               0.0               0.0            0.0   \n",
       "2             0.0               0.0               0.0            0.0   \n",
       "3             0.0               0.0               0.0            0.0   \n",
       "4             0.0               0.0               0.0            0.0   \n",
       "\n",
       "   zon afric also  zon ant col  zon babi us  zon provid gre  \n",
       "0             0.0          0.0          0.0             0.0  \n",
       "1             0.0          0.0          0.0             0.0  \n",
       "2             0.0          0.0          0.0             0.0  \n",
       "3             0.0          0.0          0.0             0.0  \n",
       "4             0.0          0.0          0.0             0.0  \n",
       "\n",
       "[5 rows x 15000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00 ct tgw</th>\n      <th>000 first print</th>\n      <th>000 photo 10</th>\n      <th>01number pag 192bind</th>\n      <th>01number pag bind</th>\n      <th>03 01number pag</th>\n      <th>03 15number pag</th>\n      <th>03 20number pag</th>\n      <th>04 01number pag</th>\n      <th>04 03number pag</th>\n      <th>...</th>\n      <th>zip princess seam</th>\n      <th>zip pullov part</th>\n      <th>zip sid pocket</th>\n      <th>zip slid comfort</th>\n      <th>zip stash pocket</th>\n      <th>zip two front</th>\n      <th>zon afric also</th>\n      <th>zon ant col</th>\n      <th>zon babi us</th>\n      <th>zon provid gre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 15000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "print(tfidf_df.shape)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the Data is Ready for Classifier Usage\n",
    "\n",
    "### Split Data into Train and Test sets (4 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dfs before creating test and train datasets\n",
    "\n",
    "tfidf_df.reset_index(inplace=True, drop=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "data = pd.concat([df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=1811)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 4:]\n",
    "y_train = train.iloc[:, 0: 4]\n",
    "X_test = test.iloc[:, 4:]\n",
    "y_test = test.iloc[:, 0: 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in each dataframe \n",
    "\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take classes as separate columns \n",
    "\n",
    "class1_train = y_train['Level_1'].astype(str)\n",
    "class1_test = y_test['Level_1'].astype(str)\n",
    "\n",
    "class2_train = y_train['Level_2'].astype(str)\n",
    "class2_test = y_test['Level_2'].astype(str)\n",
    "\n",
    "class3_train = y_train['Level_3'].astype(str)\n",
    "class3_test = y_test['Level_3'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for the three levels (8 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy:  0.6894117647058824\n"
     ]
    }
   ],
   "source": [
    "# Create and save model for level 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('accuracy: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.691764705882353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('Accuracy: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.6823529411764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier().fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('Accuracy: ', score)\n",
    "\n",
    "with open('level1.pk', 'wb') as cls:\n",
    "    pickle.dump(classifier, cls)"
   ]
  },
  {
   "source": [
    "The MultinomialNB Model classifier had the greatest accuarcy of the three classifiers tested so using that going forward for model training of class 2 and 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Create and save models for level 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 1 Category:  90A8B052\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  90A8B052  SCORE:  1.0\n",
      "Level 1 Category:  AAC8EE56\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  AAC8EE56  SCORE:  0.7727272727272727\n",
      "Level 1 Category:  96F95EEC\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  96F95EEC  SCORE:  0.7674418604651163\n",
      "Level 1 Category:  09BF5150\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  09BF5150  SCORE:  0.6\n",
      "Level 1 Category:  35E04739\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  35E04739  SCORE:  0.7354838709677419\n",
      "Level 1 Category:  B092BA29\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  B092BA29  SCORE:  0.6159420289855072\n",
      "Level 1 Category:  2CEC27F1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  2CEC27F1  SCORE:  0.9296875\n",
      "Level 1 Category:  EFEF723B\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  EFEF723B  SCORE:  0.7364341085271318\n",
      "Level 1 Category:  4513C920\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  4513C920  SCORE:  0.803921568627451\n",
      "Level 1 Category:  69286F45\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 2D5A3  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 1 Category:  D410C91A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: ACD06  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 1 Category:  57164AC1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  57164AC1  SCORE:  0.775\n",
      "Level 1 Category:  014303D1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  014303D1  SCORE:  0.7738095238095238\n",
      "Level 1 Category:  4C3D8686\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  4C3D8686  SCORE:  0.8390804597701149\n",
      "Level 1 Category:  3E1E0D78\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  3E1E0D78  SCORE:  0.875\n"
     ]
    }
   ],
   "source": [
    "# in this space you will be fitting models for the level 2 data \n",
    "#so you will want to split the test data into sub data for each classification e.g.\n",
    "\n",
    "#get unique level 1 categories\n",
    "level1cats = class1_train.unique()\n",
    "\n",
    "lvl1_cat_indexes = []\n",
    "lvl1_cat_indexes_test = []\n",
    "lvl1_unique = []\n",
    "\n",
    "for index, cat in enumerate(level1cats): \n",
    "    print('Level 1 Category: ', cat)\n",
    "    #get indexes for train data and test data\n",
    "    a = list(class1_train[class1_train == cat].index)\n",
    "    b = list(class1_test[class1_test == cat].index)\n",
    "    lvl1_cat_indexes.append(a)\n",
    "    lvl1_cat_indexes_test.append(b)\n",
    "\n",
    "    # some class 2 data only has one unique value for a particular level 1 category so can't create a model\n",
    "    if class2_train.loc[a].nunique() == 1:\n",
    "        unique_val = class2_train.loc[a].unique()[0]\n",
    "        print('ERROR: ONLY ONE UNIQUE VALUE:', unique_val, ' SO SKIP MODEL CREATION \\n')\n",
    "        #put values into array for prediction later\n",
    "        lvl1_unique.append([cat, unique_val])\n",
    "        continue\n",
    "    #create model with train data for unique level 1 category\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(X_train.loc[a], class2_train[a])\n",
    "\n",
    "    score = classifier.score(X_test.loc[b], class2_test[b])\n",
    "    print('\\n Accuracy score for LVL 1 CAT: ', cat, ' SCORE: ', score)\n",
    "\n",
    "    #save model\n",
    "    model_name = 'level2_' + cat + '.pk'\n",
    "    with open(model_name, 'wb') as cls: \n",
    "        pickle.dump(classifier, cls)\n"
   ]
  },
  {
   "source": [
    "## Create and save models for level 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 2 Category:  C719A\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  C719A  SCORE:  0.36764705882352944\n",
      "Level 2 Category:  9B69F\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  9B69F  SCORE:  0.4098360655737705\n",
      "Level 2 Category:  A04D3\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  A04D3  SCORE:  0.3225806451612903\n",
      "Level 2 Category:  C7E19\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  C7E19  SCORE:  0.4444444444444444\n",
      "Level 2 Category:  B2DB4\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  B2DB4  SCORE:  0.34210526315789475\n",
      "Level 2 Category:  5A8AB\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  5A8AB  SCORE:  0.44285714285714284\n",
      "Level 2 Category:  BAE8A\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  BAE8A  SCORE:  0.35135135135135137\n",
      "Level 2 Category:  D5531\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6253  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  F4055\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  F4055  SCORE:  0.28378378378378377\n",
      "Level 2 Category:  2D5A3\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  2D5A3  SCORE:  0.32116788321167883\n",
      "Level 2 Category:  CB803\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  CB803  SCORE:  0.359375\n",
      "Level 2 Category:  ACD06\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  ACD06  SCORE:  0.4189189189189189\n",
      "Level 2 Category:  7B638\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  7B638  SCORE:  0.5540540540540541\n",
      "Level 2 Category:  AF6B9\n",
      "ERROR: ONLY ONE UNIQUE VALUE: A104  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  7AED7\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  7AED7  SCORE:  0.425\n",
      "Level 2 Category:  ADAD6\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  ADAD6  SCORE:  0.3888888888888889\n",
      "Level 2 Category:  E69F5\n",
      "ERROR: ONLY ONE UNIQUE VALUE: DDD5  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  77F62\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  77F62  SCORE:  0.4090909090909091\n",
      "Level 2 Category:  F824F\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 7288  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  390F1\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  390F1  SCORE:  0.46835443037974683\n",
      "Level 2 Category:  31FED\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  31FED  SCORE:  0.5\n",
      "Level 2 Category:  223B2\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  223B2  SCORE:  0.35294117647058826\n",
      "Level 2 Category:  375FE\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  375FE  SCORE:  0.3088235294117647\n",
      "Level 2 Category:  08960\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 1000  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  914A1\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  914A1  SCORE:  0.36619718309859156\n",
      "Level 2 Category:  36080\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  36080  SCORE:  0.375\n",
      "Level 2 Category:  9D9EE\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  9D9EE  SCORE:  0.2894736842105263\n",
      "Level 2 Category:  94728\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  94728  SCORE:  0.43902439024390244\n",
      "Level 2 Category:  74974\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  74974  SCORE:  0.5\n",
      "Level 2 Category:  915D4\n",
      "ERROR: ONLY ONE UNIQUE VALUE: A2FA  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  02FA0\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  02FA0  SCORE:  0.48\n",
      "Level 2 Category:  E6162\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 2E14  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  5E038\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6BE5  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  6C6B1\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 3AAD  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  0864A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 96B8  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  262E7\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 29B3  SO SKIP MODEL CREATION \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get unique level 2 categories\n",
    "level2cats = class2_train.unique()\n",
    "\n",
    "lvl2_cat_indexes = []\n",
    "lvl2_cat_indexes_test = []\n",
    "lvl2_unique = []\n",
    "for index, cat in enumerate(level2cats): \n",
    "    print('Level 2 Category: ', cat)\n",
    "    #get indexes for train data and test data\n",
    "    a = list(class2_train[class2_train == cat].index)\n",
    "    b = list(class2_test[class2_test == cat].index)\n",
    "\n",
    "    lvl2_cat_indexes.append(a)\n",
    "    lvl2_cat_indexes_test.append(b)\n",
    "\n",
    "    # some class 2 data only has one unique value for a particular level 1 category so can't create a model\n",
    "    if class3_train.loc[a].nunique() == 1:\n",
    "        unique_val = class3_train.loc[a].unique()[0]\n",
    "        print('ERROR: ONLY ONE UNIQUE VALUE:', unique_val, ' SO SKIP MODEL CREATION \\n')\n",
    "        #put values into array for prediction later\n",
    "        lvl2_unique.append([cat, unique_val])\n",
    "        continue\n",
    "    #create model with train data for unique level 2 category\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(X_train.loc[a], class3_train[a])\n",
    "    score = classifier.score(X_test.loc[b], class3_test[b])\n",
    "    print('\\n Accuracy score for LVL 2 CAT: ', cat, ' SCORE: ', score)\n",
    "\n",
    "    #save model\n",
    "    model_name = 'level3_' + cat + '.pk'\n",
    "    with open(model_name, 'wb') as cls: \n",
    "        pickle.dump(classifier, cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set (8 marks)\n",
    "\n",
    "## Predict Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Level1_Pred Level2_Pred Level3_Pred\n",
       "0    3E1E0D78         NaN         NaN\n",
       "1    3E1E0D78         NaN         NaN\n",
       "2    3E1E0D78         NaN         NaN\n",
       "3    3E1E0D78         NaN         NaN\n",
       "4    57164AC1         NaN         NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Level1_Pred</th>\n      <th>Level2_Pred</th>\n      <th>Level3_Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3E1E0D78</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3E1E0D78</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3E1E0D78</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3E1E0D78</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57164AC1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Creating an empty Dataframe with column names only\n",
    "results = pd.DataFrame(columns=['Level1_Pred', 'Level2_Pred', 'Level3_Pred'])\n",
    "\n",
    "## Here we reload the saved models and use them to predict the levels\n",
    "# load model for level 1 (done for you)\n",
    "with open('level1.pk', 'rb') as nb:\n",
    "    model = pickle.load(nb)\n",
    "\n",
    "## loop through the test data, predict level 1\n",
    "level1_pred = model.predict(X_test)\n",
    "results['Level1_Pred'] = level1_pred\n",
    "results.head()\n"
   ]
  },
  {
   "source": [
    "## Predict Level 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 1 Category:  90A8B052\n",
      "Level 1 Category:  AAC8EE56\n",
      "Level 1 Category:  96F95EEC\n",
      "Level 1 Category:  09BF5150\n",
      "Level 1 Category:  35E04739\n",
      "Level 1 Category:  B092BA29\n",
      "Level 1 Category:  2CEC27F1\n",
      "Level 1 Category:  EFEF723B\n",
      "Level 1 Category:  4513C920\n",
      "Level 1 Category:  69286F45\n",
      "Unique Category - no model\n",
      "Level 1 Category:  D410C91A\n",
      "Unique Category - no model\n",
      "Level 1 Category:  57164AC1\n",
      "Level 1 Category:  014303D1\n",
      "Level 1 Category:  4C3D8686\n",
      "Level 1 Category:  3E1E0D78\n"
     ]
    }
   ],
   "source": [
    "# for each category in level 1 predictions => use that plus the model for that category to predict level 2\n",
    "\n",
    "flat_lvl1_unique = [element for sublist in lvl1_unique for element in sublist]\n",
    "\n",
    "for index, cat in enumerate(level1cats): \n",
    "    print('Level 1 Category: ', cat)\n",
    "    # get indexes\n",
    "    a = list(results[results['Level1_Pred']== cat].index)\n",
    "    # if cat is in the arrayof lvl1_unique => set predicted values to its pair\n",
    "    if cat in flat_lvl1_unique:\n",
    "        index = flat_lvl1_unique.index(cat)\n",
    "        predicted = flat_lvl1_unique[index+1]\n",
    "        print('Unique Category - no model')\n",
    "        results['Level2_Pred'].loc[a] =  predicted\n",
    "        continue\n",
    "    # get model\n",
    "    model_name = 'level2_' + cat + '.pk'\n",
    "    with open(model_name, 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "    results['Level2_Pred'].loc[a] =  model.predict(X_test.loc[a])\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Predict Level 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 2 Category:  C719A\n",
      "Level 2 Category:  9B69F\n",
      "Level 2 Category:  A04D3\n",
      "Level 2 Category:  C7E19\n",
      "Level 2 Category:  B2DB4\n",
      "Level 2 Category:  5A8AB\n",
      "Level 2 Category:  BAE8A\n",
      "Level 2 Category:  D5531\n",
      "Unique Category - no model\n",
      "Level 2 Category:  F4055\n",
      "Level 2 Category:  2D5A3\n",
      "Level 2 Category:  CB803\n",
      "Level 2 Category:  ACD06\n",
      "Level 2 Category:  7B638\n",
      "Level 2 Category:  AF6B9\n",
      "Unique Category - no model\n",
      "Level 2 Category:  7AED7\n",
      "Level 2 Category:  ADAD6\n",
      "Level 2 Category:  E69F5\n",
      "Unique Category - no model\n",
      "Level 2 Category:  77F62\n",
      "Level 2 Category:  F824F\n",
      "Unique Category - no model\n",
      "Level 2 Category:  390F1\n",
      "Level 2 Category:  31FED\n",
      "Level 2 Category:  223B2\n",
      "Level 2 Category:  375FE\n",
      "Level 2 Category:  08960\n",
      "Unique Category - no model\n",
      "Level 2 Category:  914A1\n",
      "Level 2 Category:  36080\n",
      "Level 2 Category:  9D9EE\n",
      "Level 2 Category:  94728\n",
      "Level 2 Category:  74974\n",
      "Level 2 Category:  915D4\n",
      "Unique Category - no model\n",
      "Level 2 Category:  02FA0\n",
      "Level 2 Category:  E6162\n",
      "Unique Category - no model\n",
      "Level 2 Category:  5E038\n",
      "Unique Category - no model\n",
      "Level 2 Category:  6C6B1\n",
      "Unique Category - no model\n",
      "Level 2 Category:  0864A\n",
      "Unique Category - no model\n",
      "Level 2 Category:  262E7\n",
      "Unique Category - no model\n"
     ]
    }
   ],
   "source": [
    "# for each category in level 1 predictions => use that plus the model for that category to predict level 2\n",
    "\n",
    "flat_lvl2_unique = [element for sublist in lvl2_unique for element in sublist]\n",
    "\n",
    "for index, cat in enumerate(level2cats): \n",
    "    print('Level 2 Category: ', cat)\n",
    "    # get indexes\n",
    "    a = list(results[results['Level2_Pred']== cat].index)\n",
    "    # if category is in the arraykof lvl1_unique => set predicted values to its pair\n",
    "    if cat in flat_lvl2_unique:\n",
    "        index = flat_lvl2_unique.index(cat)\n",
    "        predicted = flat_lvl2_unique[index+1]\n",
    "        print('Unique Category - no model')\n",
    "        results['Level3_Pred'].loc[a] =  predicted\n",
    "        continue\n",
    "    # get model\n",
    "    model_name = 'level3_' + cat + '.pk'\n",
    "    with open(model_name, 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "    results['Level3_Pred'].loc[a] =  model.predict(X_test.loc[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Level1_Pred Level2_Pred Level3_Pred\n",
       "0       3E1E0D78       9D9EE        05A0\n",
       "1       3E1E0D78       9D9EE        05A0\n",
       "2       3E1E0D78       9D9EE        05A0\n",
       "3       3E1E0D78       9D9EE        05A0\n",
       "4       57164AC1       7B638        2C26\n",
       "...          ...         ...         ...\n",
       "1695    3E1E0D78       9D9EE        05A0\n",
       "1696    3E1E0D78       9D9EE        05A0\n",
       "1697    3E1E0D78       9D9EE        05A0\n",
       "1698    4C3D8686       74974        DAEA\n",
       "1699    AAC8EE56       914A1        D97D\n",
       "\n",
       "[1700 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Level1_Pred</th>\n      <th>Level2_Pred</th>\n      <th>Level3_Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>05A0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>05A0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>05A0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>05A0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57164AC1</td>\n      <td>7B638</td>\n      <td>2C26</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>05A0</td>\n    </tr>\n    <tr>\n      <th>1696</th>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>05A0</td>\n    </tr>\n    <tr>\n      <th>1697</th>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>05A0</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>4C3D8686</td>\n      <td>74974</td>\n      <td>DAEA</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>AAC8EE56</td>\n      <td>914A1</td>\n      <td>D97D</td>\n    </tr>\n  </tbody>\n</table>\n<p>1700 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on each level (4 marks)\n",
    "Now you have the predictions for each level (in the test data), and you also have the actual levels, you can compute the accurcay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVEL 1 ACCURACY:  0.6823529411764706\n"
     ]
    }
   ],
   "source": [
    "# Level 1 accuracy\n",
    "print('LEVEL 1 ACCURACY: ', accuracy_score(y_test['Level_1'], level1_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVEL 2 ACCURACY:  0.6064705882352941\n"
     ]
    }
   ],
   "source": [
    "# Level 2 accuracy\n",
    "print('LEVEL 2 ACCURACY: ', accuracy_score(y_test['Level_2'], results['Level2_Pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVEL 3 ACCURACY:  0.23294117647058823\n"
     ]
    }
   ],
   "source": [
    "# Level 3 accuracy\n",
    "print('LEVEL 3 ACCURACY: ', accuracy_score(y_test['Level_3'], results['Level3_Pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python396jvsc74a57bd0b874ae6ca3bf8380d01ff748c279caa87bf096af67f0e2a4c58ac8b205c3f032",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "b874ae6ca3bf8380d01ff748c279caa87bf096af67f0e2a4c58ac8b205c3f032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}