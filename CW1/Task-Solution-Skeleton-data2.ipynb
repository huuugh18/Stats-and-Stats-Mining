{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.spatial import distance_matrix\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and explore the data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                              Description   Level_1 Level_2  \\\n",
       "count                                               10627     10639   10639   \n",
       "unique                                               9668        15      36   \n",
       "top     glory gorg col fing complet outfit express moo...  B092BA29   2D5A3   \n",
       "freq                                                   24       900     797   \n",
       "\n",
       "       Level_3  \n",
       "count    10639  \n",
       "unique      94  \n",
       "top       28A7  \n",
       "freq       332  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>10627</td>\n      <td>10639</td>\n      <td>10639</td>\n      <td>10639</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>9668</td>\n      <td>15</td>\n      <td>36</td>\n      <td>94</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>glory gorg col fing complet outfit express moo...</td>\n      <td>B092BA29</td>\n      <td>2D5A3</td>\n      <td>28A7</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>24</td>\n      <td>900</td>\n      <td>797</td>\n      <td>332</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "data = pd.read_csv('product-category-dataset-improved.csv')\n",
    "df = pd.DataFrame(data)\n",
    "df.describe()\n",
    "\n",
    "# 15 level_1 classes # 36 level_2 classes #94 level_3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0  gerb cap help keep littl on head cov warm day ...  09BF5150   C7E19    FDCF\n",
       "1  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    ED0D\n",
       "2  tut ballet anym leap foxy fash ruffl tul toddl...  09BF5150   C7E19    D06E\n",
       "3  newborn inf toddl boy hoody jacket oshkosh b g...  2CEC27F1   ADAD6    98CF\n",
       "4  easy keep feel warm cozy inf toddl girl hoody ...  2CEC27F1   ADAD6    3918"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>gerb cap help keep littl on head cov warm day ...</td>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>FDCF</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>ED0D</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tut ballet anym leap foxy fash ruffl tul toddl...</td>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>D06E</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>newborn inf toddl boy hoody jacket oshkosh b g...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>98CF</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>easy keep feel warm cozy inf toddl girl hoody ...</td>\n      <td>2CEC27F1</td>\n      <td>ADAD6</td>\n      <td>3918</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with Missing Data (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "There are 12 missing indices\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[1063, 3434, 3458, 7754, 7788, 7796, 7808, 7859, 7936, 7962, 7988, 8004]"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# Check if data has missing values in the Description column\n",
    "\n",
    "missing_descriptions_indices = df[df['Description'].isnull()].index.tolist()\n",
    "print('There are', len(missing_descriptions_indices), 'missing indices')\n",
    "missing_descriptions_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(10627, 4)"
      ]
     },
     "metadata": {},
     "execution_count": 92
    }
   ],
   "source": [
    "# Remove missing descriptions rows from dataframe\n",
    "df = df[df['Description'].notna()]\n",
    "df.shape\n",
    "#shape is 10627 rows which is 12 less than original 10639 so know we have dropped the correct amount of rows from the dataframe"
   ]
  },
  {
   "source": [
    "## Create subset of data to workwith as dataset too large"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8500, 4)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         Description   Level_1 Level_2 Level_3\n",
       "0  comfort polo shirt nee disappear chil hit air ...  4513C920   F4055    5B02\n",
       "1  item feat long sleev hood ful zip left intern ...  57164AC1   7B638    2C26\n",
       "2  rich col shim effect dram ey catch look includ...  3E1E0D78   9D9EE    818C\n",
       "3                                 5 oz 15ml nail pol  D410C91A   ACD06    33D1\n",
       "4  st catherin bologn med gold fil st catherin bo...  96F95EEC   36080    C563"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Description</th>\n      <th>Level_1</th>\n      <th>Level_2</th>\n      <th>Level_3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>comfort polo shirt nee disappear chil hit air ...</td>\n      <td>4513C920</td>\n      <td>F4055</td>\n      <td>5B02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>item feat long sleev hood ful zip left intern ...</td>\n      <td>57164AC1</td>\n      <td>7B638</td>\n      <td>2C26</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>rich col shim effect dram ey catch look includ...</td>\n      <td>3E1E0D78</td>\n      <td>9D9EE</td>\n      <td>818C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5 oz 15ml nail pol</td>\n      <td>D410C91A</td>\n      <td>ACD06</td>\n      <td>33D1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>st catherin bologn med gold fil st catherin bo...</td>\n      <td>96F95EEC</td>\n      <td>36080</td>\n      <td>C563</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "df = df.sample(n = 8500)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "# check shape to make sure correct transformation\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Classes where the number of instances is < 10 (4 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "35E04739    722\nAAC8EE56    721\nB092BA29    710\n2CEC27F1    709\n57164AC1    701\n09BF5150    642\nEFEF723B    640\n69286F45    631\n3E1E0D78    467\n4C3D8686    463\n96F95EEC    458\n4513C920    452\n014303D1    404\n90A8B052    395\nD410C91A    385\nName: Level_1, dtype: int64\nNumber of Unique Level 1 Categories:  15\n"
     ]
    }
   ],
   "source": [
    "# Apply to Level_1 \n",
    "print(df.Level_1.value_counts())\n",
    "print('Number of Unique Level 1 Categories: ', df.Level_1.nunique())\n",
    "# No classes have less than 10 instances"
   ]
  },
  {
   "source": [
    "There are 15 level 1 classes all of which have more than 10 instances. \n",
    "No classes will be dropped from level 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Unique Level 2 Categories:  36\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2D5A3    631\n",
       "ACD06    385\n",
       "C719A    378\n",
       "9D9EE    374\n",
       "BAE8A    368\n",
       "B2DB4    365\n",
       "9B69F    364\n",
       "5A8AB    360\n",
       "C7E19    359\n",
       "914A1    357\n",
       "390F1    357\n",
       "CB803    357\n",
       "74974    356\n",
       "94728    353\n",
       "375FE    350\n",
       "ADAD6    341\n",
       "7B638    337\n",
       "A04D3    315\n",
       "F4055    292\n",
       "7AED7    224\n",
       "02FA0    215\n",
       "77F62    180\n",
       "36080    143\n",
       "223B2    107\n",
       "E6162     93\n",
       "E69F5     88\n",
       "5E038     85\n",
       "31FED     72\n",
       "D5531     68\n",
       "262E7     57\n",
       "F824F     57\n",
       "915D4     33\n",
       "6C6B1     26\n",
       "AF6B9     25\n",
       "08960     17\n",
       "0864A     11\n",
       "Name: Level_2, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "source": [
    "# Apply to Level_2\n",
    "\n",
    "# create mask based on value counts\n",
    "mask_2 = df.Level_2.value_counts()\n",
    "# apply mask to dataset\n",
    "df = df[df['Level_2'].isin(mask_2.index[mask_2>9])]\n",
    "print('Number of Unique Level 2 Categories: ', df.Level_2.nunique())\n",
    "\n",
    "#confirm no classes left have fewer than 10 instances\n",
    "df.Level_2.value_counts()"
   ]
  },
  {
   "source": [
    "All remaining level 2 classes have more than 10 instances."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of Unique Level 3 Categories:  94\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "28A7    258\n",
       "2CFE    185\n",
       "BB6B    180\n",
       "AA6B    175\n",
       "5912    173\n",
       "       ... \n",
       "74C9     21\n",
       "98A8     19\n",
       "1000     17\n",
       "D55B     16\n",
       "96B8     11\n",
       "Name: Level_3, Length: 94, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "# Apply to Level_3\n",
    "\n",
    "#create mask \n",
    "mask_3 = df.Level_3.value_counts()\n",
    "#apply mask\n",
    "df = df[df['Level_3'].isin(mask_3.index[mask_3>9])]\n",
    "\n",
    "print('Number of Unique Level 3 Categories: ', df.Level_3.nunique())\n",
    "\n",
    "# check value counts all above 10 instances\n",
    "df.Level_3.value_counts()"
   ]
  },
  {
   "source": [
    "All remaining level 3 classes have more than 10 instances."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's write a Function to Prepare Text (4 marks)\n",
    "We will apply it to our DataFrame later on\n",
    "\n",
    "* This function receives a text string and performs the following:\n",
    "* Convert text to lower case\n",
    "* Remove punctuation marks\n",
    "* Apply stemming using the popular Snowball or Porter Stemmer (optional)\n",
    "* Apply NGram Tokenisation\n",
    "* Return the tokenised text as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\hugho\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "import re\n",
    "snowball_stemmer = SnowballStemmer(language='english')\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "def scrub_words(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'[_]','', text)\n",
    "    return text\n",
    "\n",
    "def process_text(text, n = 3):\n",
    "    # 1. Convert text to lower case and remove all punctuation\n",
    "    scrubbed_text =scrub_words(text)                \n",
    "    \n",
    "    # 2. Tokenize words\n",
    "    token_words = word_tokenize(scrubbed_text)      \n",
    "\n",
    "    #3. Apply stemming\n",
    "    stem_words = [snowball_stemmer.stem(w) for w in token_words] \n",
    "    \n",
    "    # 4. Apply Ngram Tokenisation\n",
    "    n_grams = ngrams(stem_words, n)                 \n",
    "    return [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "def process_text2(text):\n",
    "    # 1. Convert text to lower case and remove all punctuation\n",
    "    scrubbed_text =scrub_words(text)                \n",
    "    \n",
    "    # 2. Tokenize words\n",
    "    token_words = word_tokenize(scrubbed_text)      \n",
    "\n",
    "    #3. Apply stemming\n",
    "    stem_words = [snowball_stemmer.stem(w) for w in token_words] \n",
    "    \n",
    "    # 4. Apply Ngram Tokenisation\n",
    "    return ' '.join(stem_words)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'here were test the processtext function result are as follow'"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "source": [
    "# Here is an example function call\n",
    "process_text(\"Here we're testing the process_text function, results are as follows:\")\n",
    "process_text2(\"Here we're testing the process_text function, results are as follows:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's apply TF-IDF to extract features from plain text (10 marks)\n",
    "\n",
    "### Here you apply the process_text function to the Description column of the data\n",
    "### Then you pass the results to the bag of words tranformer\n",
    "### See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from itertools import chain"
   ]
  },
  {
   "source": [
    "## Use TFIDF Vectorizer which combines the process of using Count Vectorizer followed and TFIDF Transformer into one Process"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3,3), preprocessor=process_text2, max_features=15000)\n",
    "\n",
    "X = vectorizer.fit_transform(df['Description'].values)\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.todense(), columns=vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8500, 15000)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   00 ct tgw  000 first print  000 photo 10  01number pag 192bind  \\\n",
       "0        0.0              0.0           0.0                   0.0   \n",
       "1        0.0              0.0           0.0                   0.0   \n",
       "2        0.0              0.0           0.0                   0.0   \n",
       "3        0.0              0.0           0.0                   0.0   \n",
       "4        0.0              0.0           0.0                   0.0   \n",
       "\n",
       "   01number pag bind  02 05number pag  03 13number pag  03 15number pag  \\\n",
       "0                0.0              0.0              0.0              0.0   \n",
       "1                0.0              0.0              0.0              0.0   \n",
       "2                0.0              0.0              0.0              0.0   \n",
       "3                0.0              0.0              0.0              0.0   \n",
       "4                0.0              0.0              0.0              0.0   \n",
       "\n",
       "   04 01number pag  04 27number pag  ...  zip pocket two  zip sid pocket  \\\n",
       "0              0.0              0.0  ...        0.000000             0.0   \n",
       "1              0.0              0.0  ...        0.136403             0.0   \n",
       "2              0.0              0.0  ...        0.000000             0.0   \n",
       "3              0.0              0.0  ...        0.000000             0.0   \n",
       "4              0.0              0.0  ...        0.000000             0.0   \n",
       "\n",
       "   zip stash pocket  zip two front  ziploc brand dispo  zircon ston ring  \\\n",
       "0               0.0            0.0                 0.0               0.0   \n",
       "1               0.0            0.0                 0.0               0.0   \n",
       "2               0.0            0.0                 0.0               0.0   \n",
       "3               0.0            0.0                 0.0               0.0   \n",
       "4               0.0            0.0                 0.0               0.0   \n",
       "\n",
       "   zon afric also  zon ant col  zon babi us  zon provid gre  \n",
       "0             0.0          0.0          0.0             0.0  \n",
       "1             0.0          0.0          0.0             0.0  \n",
       "2             0.0          0.0          0.0             0.0  \n",
       "3             0.0          0.0          0.0             0.0  \n",
       "4             0.0          0.0          0.0             0.0  \n",
       "\n",
       "[5 rows x 15000 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>00 ct tgw</th>\n      <th>000 first print</th>\n      <th>000 photo 10</th>\n      <th>01number pag 192bind</th>\n      <th>01number pag bind</th>\n      <th>02 05number pag</th>\n      <th>03 13number pag</th>\n      <th>03 15number pag</th>\n      <th>04 01number pag</th>\n      <th>04 27number pag</th>\n      <th>...</th>\n      <th>zip pocket two</th>\n      <th>zip sid pocket</th>\n      <th>zip stash pocket</th>\n      <th>zip two front</th>\n      <th>ziploc brand dispo</th>\n      <th>zircon ston ring</th>\n      <th>zon afric also</th>\n      <th>zon ant col</th>\n      <th>zon babi us</th>\n      <th>zon provid gre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.136403</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 15000 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "source": [
    "print(tfidf_df.shape)\n",
    "tfidf_df.head()"
   ]
  },
  {
   "source": [
    "## Check to see if they are the same"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_df_one = pd.DataFrame(first_descrip_vector.T.todense(), index=feature_names, columns=['tfidf'])\n",
    "# # print(tfidf_df_one.sort_values(by=['tfidf'],ascending=False))\n",
    "\n",
    "# tfidf_df2_one = pd.DataFrame(X2[0].T.todense(), index=feature_names, columns=['tfidf'])\n",
    "# # print(tfidf_df2_one.sort_values(by=['tfidf'],ascending=False))\n",
    "\n",
    "\n",
    "# if ((tfidf_df_one.values == tfidf_df2_one.values).all()):\n",
    "#     print('Arrays are equal showing tfidf vectorizer returns same result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can use `.transform` on our Bag-of-Words (bow) transformed object and transform the entire DataFrame of text file contents. Let's go ahead and check out how the bag-of-words counts for the entire corpus in a large, sparse matrix:\n",
    "\n",
    "After that you pass the result of the previous step to sklearn's TfidfTransformer  \n",
    "which will convert them into a feature matrix  \n",
    "See here: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "\n",
    "The resulting matrix is in sparse format, we can transform it into dense  \n",
    "Code prepared for you so you can see what results look like\n",
    "\n",
    "This is an example result, the matrix will contain lots of zero values, that is expected.  \n",
    "Some values will be non-zero\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the Data is Ready for Classifier Usage\n",
    "\n",
    "### Split Data into Train and Test sets (4 marks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine dfs before creating test and train datasets\n",
    "\n",
    "tfidf_df.reset_index(inplace=True, drop=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "data = pd.concat([df, tfidf_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=1811)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.iloc[:, 4:]\n",
    "y_train = train.iloc[:, 0: 4]\n",
    "X_test = test.iloc[:, 4:]\n",
    "y_test = test.iloc[:, 0: 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index in each dataframe \n",
    "\n",
    "X_train.reset_index(inplace=True, drop=True)\n",
    "X_test.reset_index(inplace=True, drop=True)\n",
    "y_train.reset_index(inplace=True, drop=True)\n",
    "y_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take classes as separate columns \n",
    "\n",
    "class1_train = y_train['Level_1'].astype(str)\n",
    "class1_test = y_test['Level_1'].astype(str)\n",
    "\n",
    "class2_train = y_train['Level_2'].astype(str)\n",
    "class2_test = y_test['Level_2'].astype(str)\n",
    "\n",
    "class3_train = y_train['Level_3'].astype(str)\n",
    "class3_test = y_test['Level_3'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training for the three levels (8 marks)\n",
    "\n",
    "naive bayes class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy:  0.6994117647058824\n"
     ]
    }
   ],
   "source": [
    "# Create and save model for level 1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('accuracy: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.7041176470588235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('Accuracy: ', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.6717647058823529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier().fit(X_train, class1_train)\n",
    "score = classifier.score(X_test, class1_test)\n",
    "print('Accuracy: ', score)\n",
    "\n",
    "with open('level1.pk', 'wb') as cls:\n",
    "    pickle.dump(classifier, cls)"
   ]
  },
  {
   "source": [
    "The MultinomialNB Model classifier had the greatest accuarcy of the three classifiers tested so using that going forward for model training of class 2 and 3."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Create and save models for level 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 1 Category:  EFEF723B\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  EFEF723B  SCORE:  0.852112676056338\n",
      "Level 1 Category:  90A8B052\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  90A8B052  SCORE:  1.0\n",
      "Level 1 Category:  69286F45\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 2D5A3  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 1 Category:  96F95EEC\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  96F95EEC  SCORE:  0.8888888888888888\n",
      "Level 1 Category:  4C3D8686\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  4C3D8686  SCORE:  0.7835051546391752\n",
      "Level 1 Category:  4513C920\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  4513C920  SCORE:  0.7333333333333333\n",
      "Level 1 Category:  35E04739\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  35E04739  SCORE:  0.8223684210526315\n",
      "Level 1 Category:  09BF5150\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  09BF5150  SCORE:  0.664\n",
      "Level 1 Category:  57164AC1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  57164AC1  SCORE:  0.7248322147651006\n",
      "Level 1 Category:  AAC8EE56\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  AAC8EE56  SCORE:  0.7894736842105263\n",
      "Level 1 Category:  014303D1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  014303D1  SCORE:  0.9090909090909091\n",
      "Level 1 Category:  2CEC27F1\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  2CEC27F1  SCORE:  0.927536231884058\n",
      "Level 1 Category:  3E1E0D78\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  3E1E0D78  SCORE:  0.8695652173913043\n",
      "Level 1 Category:  B092BA29\n",
      "\n",
      " Accuracy score for LVL 1 CAT:  B092BA29  SCORE:  0.5362318840579711\n",
      "Level 1 Category:  D410C91A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: ACD06  SO SKIP MODEL CREATION \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['69286F45', '2D5A3'], ['D410C91A', 'ACD06']]"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "# in this space you will be fitting models for the level 2 data \n",
    "#so you will want to split the test data into sub data for each classification e.g.\n",
    "\n",
    "#get unique level 1 categories\n",
    "level1cats = class1_train.unique()\n",
    "\n",
    "lvl1_cat_indexes = []\n",
    "lvl1_cat_indexes_test = []\n",
    "lvl1_unique = []\n",
    "\n",
    "for index, cat in enumerate(level1cats): \n",
    "    print('Level 1 Category: ', cat)\n",
    "    #get indexes for train data and test data\n",
    "    a = list(class1_train[class1_train == cat].index)\n",
    "    b = list(class1_test[class1_test == cat].index)\n",
    "    lvl1_cat_indexes.append(a)\n",
    "    lvl1_cat_indexes_test.append(b)\n",
    "\n",
    "    # some class 2 data only has one unique value for a particular level 1 category so can't create a model\n",
    "    if class2_train.loc[a].nunique() == 1:\n",
    "        unique_val = class2_train.loc[a].unique()[0]\n",
    "        print('ERROR: ONLY ONE UNIQUE VALUE:', unique_val, ' SO SKIP MODEL CREATION \\n')\n",
    "        #put values into array for prediction later\n",
    "        lvl1_unique.append([cat, unique_val])\n",
    "        continue\n",
    "    #create model with train data for unique level 1 category\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(X_train.loc[a], class2_train[a])\n",
    "\n",
    "    score = classifier.score(X_test.loc[b], class2_test[b])\n",
    "    print('\\n Accuracy score for LVL 1 CAT: ', cat, ' SCORE: ', score)\n",
    "\n",
    "    #save model\n",
    "    model_name = 'level2_' + cat + '.pk'\n",
    "    with open(model_name, 'wb') as cls: \n",
    "        pickle.dump(classifier, cls)\n",
    "    # limit = 5\n",
    "    # if index == limit: \n",
    "    #     break\n",
    "\n",
    "# cat 69286F45 unique val 2D5A3\n",
    "# D410C91A => ACD06\n",
    "lvl1_unique"
   ]
  },
  {
   "source": [
    "## Create and save models for level 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 2 Category:  02FA0\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  02FA0  SCORE:  0.35294117647058826\n",
      "Level 2 Category:  C719A\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  C719A  SCORE:  0.43548387096774194\n",
      "Level 2 Category:  2D5A3\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  2D5A3  SCORE:  0.4140625\n",
      "Level 2 Category:  A04D3\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  A04D3  SCORE:  0.3611111111111111\n",
      "Level 2 Category:  74974\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  74974  SCORE:  0.4084507042253521\n",
      "Level 2 Category:  D5531\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6253  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  31FED\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  31FED  SCORE:  0.75\n",
      "Level 2 Category:  F4055\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  F4055  SCORE:  0.22807017543859648\n",
      "Level 2 Category:  390F1\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  390F1  SCORE:  0.4230769230769231\n",
      "Level 2 Category:  C7E19\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  C7E19  SCORE:  0.33766233766233766\n",
      "Level 2 Category:  94728\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  94728  SCORE:  0.4473684210526316\n",
      "Level 2 Category:  7B638\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  7B638  SCORE:  0.5070422535211268\n",
      "Level 2 Category:  CB803\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  CB803  SCORE:  0.4146341463414634\n",
      "Level 2 Category:  914A1\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  914A1  SCORE:  0.575\n",
      "Level 2 Category:  7AED7\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  7AED7  SCORE:  0.4878048780487805\n",
      "Level 2 Category:  BAE8A\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  BAE8A  SCORE:  0.3698630136986301\n",
      "Level 2 Category:  9D9EE\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  9D9EE  SCORE:  0.33766233766233766\n",
      "Level 2 Category:  ADAD6\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  ADAD6  SCORE:  0.49230769230769234\n",
      "Level 2 Category:  375FE\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  375FE  SCORE:  0.3728813559322034\n",
      "Level 2 Category:  5E038\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 6BE5  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  77F62\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  77F62  SCORE:  0.36\n",
      "Level 2 Category:  9B69F\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  9B69F  SCORE:  0.4166666666666667\n",
      "Level 2 Category:  B2DB4\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  B2DB4  SCORE:  0.4594594594594595\n",
      "Level 2 Category:  F824F\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 7288  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  ACD06\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  ACD06  SCORE:  0.5373134328358209\n",
      "Level 2 Category:  5A8AB\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  5A8AB  SCORE:  0.5316455696202531\n",
      "Level 2 Category:  36080\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  36080  SCORE:  0.5185185185185185\n",
      "Level 2 Category:  AF6B9\n",
      "ERROR: ONLY ONE UNIQUE VALUE: A104  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  E69F5\n",
      "ERROR: ONLY ONE UNIQUE VALUE: DDD5  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  262E7\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 29B3  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  E6162\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 2E14  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  6C6B1\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 3AAD  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  08960\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 1000  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  915D4\n",
      "ERROR: ONLY ONE UNIQUE VALUE: A2FA  SO SKIP MODEL CREATION \n",
      "\n",
      "Level 2 Category:  223B2\n",
      "\n",
      " Accuracy score for LVL 2 CAT:  223B2  SCORE:  0.5\n",
      "Level 2 Category:  0864A\n",
      "ERROR: ONLY ONE UNIQUE VALUE: 96B8  SO SKIP MODEL CREATION \n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11, 36)"
      ]
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "# get unique level 2 categories\n",
    "level2cats = class2_train.unique()\n",
    "\n",
    "lvl2_cat_indexes = []\n",
    "lvl2_cat_indexes_test = []\n",
    "lvl2_unique = []\n",
    "for index, cat in enumerate(level2cats): \n",
    "    print('Level 2 Category: ', cat)\n",
    "    #get indexes for train data and test data\n",
    "    a = list(class2_train[class2_train == cat].index)\n",
    "    b = list(class2_test[class2_test == cat].index)\n",
    "\n",
    "    lvl2_cat_indexes.append(a)\n",
    "    lvl2_cat_indexes_test.append(b)\n",
    "\n",
    "    # some class 2 data only has one unique value for a particular level 1 category so can't create a model\n",
    "    if class3_train.loc[a].nunique() == 1:\n",
    "        unique_val = class3_train.loc[a].unique()[0]\n",
    "        print('ERROR: ONLY ONE UNIQUE VALUE:', unique_val, ' SO SKIP MODEL CREATION \\n')\n",
    "        #put values into array for prediction later\n",
    "        lvl2_unique.append([cat, unique_val])\n",
    "        continue\n",
    "    #create model with train data for unique level 2 category\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(X_train.loc[a], class3_train[a])\n",
    "    score = classifier.score(X_test.loc[b], class3_test[b])\n",
    "    print('\\n Accuracy score for LVL 2 CAT: ', cat, ' SCORE: ', score)\n",
    "\n",
    "    #save model\n",
    "    model_name = 'level3_' + cat + '.pk'\n",
    "    with open(model_name, 'wb') as cls: \n",
    "        pickle.dump(classifier, cls)\n",
    "    # limit = 2\n",
    "    # if index == limit: \n",
    "    #     break\n",
    "\n",
    "len(lvl2_unique), len(level2cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the test set (8 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  Level1_Pred Level2_Pred Level3_Pred\n",
       "0    35E04739         NaN         NaN\n",
       "1    014303D1         NaN         NaN\n",
       "2    35E04739         NaN         NaN\n",
       "3    AAC8EE56         NaN         NaN\n",
       "4    4513C920         NaN         NaN"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Level1_Pred</th>\n      <th>Level2_Pred</th>\n      <th>Level3_Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>014303D1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35E04739</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAC8EE56</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4513C920</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "# Creating an empty Dataframe with column names only\n",
    "results = pd.DataFrame(columns=['Level1_Pred', 'Level2_Pred', 'Level3_Pred'])\n",
    "\n",
    "## Here we reload the saved models and use them to predict the levels\n",
    "# load model for level 1 (done for you)\n",
    "with open('level1.pk', 'rb') as nb:\n",
    "    model = pickle.load(nb)\n",
    "\n",
    "## loop through the test data, predict level 1\n",
    "level1_pred = model.predict(X_test)\n",
    "results['Level1_Pred'] = level1_pred\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 1 Category:  EFEF723B\n",
      "Level 1 Category:  90A8B052\n",
      "Level 1 Category:  69286F45\n",
      "Unique Category - no model\n",
      "Level 1 Category:  96F95EEC\n",
      "Level 1 Category:  4C3D8686\n",
      "Level 1 Category:  4513C920\n",
      "Level 1 Category:  35E04739\n",
      "Level 1 Category:  09BF5150\n",
      "Level 1 Category:  57164AC1\n",
      "Level 1 Category:  AAC8EE56\n",
      "Level 1 Category:  014303D1\n",
      "Level 1 Category:  2CEC27F1\n",
      "Level 1 Category:  3E1E0D78\n",
      "Level 1 Category:  B092BA29\n",
      "Level 1 Category:  D410C91A\n",
      "Unique Category - no model\n"
     ]
    }
   ],
   "source": [
    "# Predict Level 2\n",
    "\n",
    "# for each category in level 1 predictions => use that plus the model for that category to predict level 2\n",
    "\n",
    "flat_lvl1_unique = [element for sublist in lvl1_unique for element in sublist]\n",
    "\n",
    "for index, cat in enumerate(level1cats): \n",
    "    print('Level 1 Category: ', cat)\n",
    "    # get indexes\n",
    "    a = list(results[results['Level1_Pred']== cat].index)\n",
    "    # if cat is in the arrayof lvl1_unique => set predicted values to its pair\n",
    "    if cat in flat_lvl1_unique:\n",
    "        index = flat_lvl1_unique.index(cat)\n",
    "        predicted = flat_lvl1_unique[index+1]\n",
    "        print('Unique Category - no model')\n",
    "        results['Level2_Pred'].loc[a] =  predicted\n",
    "        continue\n",
    "    # get model\n",
    "    model_name = 'level2_' + cat + '.pk'\n",
    "    with open(model_name, 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "    results['Level2_Pred'].loc[a] =  model.predict(X_test.loc[a])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Level 2 Category:  02FA0\n",
      "Level 2 Category:  C719A\n",
      "Level 2 Category:  2D5A3\n",
      "Level 2 Category:  A04D3\n",
      "Level 2 Category:  74974\n",
      "Level 2 Category:  D5531\n",
      "Unique Category - no model\n",
      "Level 2 Category:  31FED\n",
      "Level 2 Category:  F4055\n",
      "Level 2 Category:  390F1\n",
      "Level 2 Category:  C7E19\n",
      "Level 2 Category:  94728\n",
      "Level 2 Category:  7B638\n",
      "Level 2 Category:  CB803\n",
      "Level 2 Category:  914A1\n",
      "Level 2 Category:  7AED7\n",
      "Level 2 Category:  BAE8A\n",
      "Level 2 Category:  9D9EE\n",
      "Level 2 Category:  ADAD6\n",
      "Level 2 Category:  375FE\n",
      "Level 2 Category:  5E038\n",
      "Unique Category - no model\n",
      "Level 2 Category:  77F62\n",
      "Level 2 Category:  9B69F\n",
      "Level 2 Category:  B2DB4\n",
      "Level 2 Category:  F824F\n",
      "Unique Category - no model\n",
      "Level 2 Category:  ACD06\n",
      "Level 2 Category:  5A8AB\n",
      "Level 2 Category:  36080\n",
      "Level 2 Category:  AF6B9\n",
      "Unique Category - no model\n",
      "Level 2 Category:  E69F5\n",
      "Unique Category - no model\n",
      "Level 2 Category:  262E7\n",
      "Unique Category - no model\n",
      "Level 2 Category:  E6162\n",
      "Unique Category - no model\n",
      "Level 2 Category:  6C6B1\n",
      "Unique Category - no model\n",
      "Level 2 Category:  08960\n",
      "Unique Category - no model\n",
      "Level 2 Category:  915D4\n",
      "Unique Category - no model\n",
      "Level 2 Category:  223B2\n",
      "Level 2 Category:  0864A\n",
      "Unique Category - no model\n"
     ]
    }
   ],
   "source": [
    "# Predict Level 3\n",
    "\n",
    "# for each category in level 1 predictions => use that plus the model for that category to predict level 2\n",
    "\n",
    "flat_lvl2_unique = [element for sublist in lvl2_unique for element in sublist]\n",
    "\n",
    "for index, cat in enumerate(level2cats): \n",
    "    print('Level 2 Category: ', cat)\n",
    "    # get indexes\n",
    "    a = list(results[results['Level2_Pred']== cat].index)\n",
    "    # if category is in the arraykof lvl1_unique => set predicted values to its pair\n",
    "    if cat in flat_lvl2_unique:\n",
    "        index = flat_lvl2_unique.index(cat)\n",
    "        predicted = flat_lvl2_unique[index+1]\n",
    "        print('Unique Category - no model')\n",
    "        results['Level3_Pred'].loc[a] =  predicted\n",
    "        continue\n",
    "    # get model\n",
    "    model_name = 'level3_' + cat + '.pk'\n",
    "    with open(model_name, 'rb') as nb:\n",
    "        model = pickle.load(nb)\n",
    "    results['Level3_Pred'].loc[a] =  model.predict(X_test.loc[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     Level1_Pred Level2_Pred Level3_Pred\n",
       "0       35E04739       B2DB4        21DA\n",
       "1       014303D1       7AED7        BBA5\n",
       "2       35E04739       390F1        6856\n",
       "3       AAC8EE56       914A1        D97D\n",
       "4       4513C920       F4055        5B02\n",
       "...          ...         ...         ...\n",
       "1695    AAC8EE56       914A1        D97D\n",
       "1696    4C3D8686       223B2        8FEF\n",
       "1697    09BF5150       C7E19        D06E\n",
       "1698    09BF5150       C7E19        D06E\n",
       "1699    D410C91A       ACD06        9203\n",
       "\n",
       "[1700 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Level1_Pred</th>\n      <th>Level2_Pred</th>\n      <th>Level3_Pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35E04739</td>\n      <td>B2DB4</td>\n      <td>21DA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>014303D1</td>\n      <td>7AED7</td>\n      <td>BBA5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35E04739</td>\n      <td>390F1</td>\n      <td>6856</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAC8EE56</td>\n      <td>914A1</td>\n      <td>D97D</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4513C920</td>\n      <td>F4055</td>\n      <td>5B02</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1695</th>\n      <td>AAC8EE56</td>\n      <td>914A1</td>\n      <td>D97D</td>\n    </tr>\n    <tr>\n      <th>1696</th>\n      <td>4C3D8686</td>\n      <td>223B2</td>\n      <td>8FEF</td>\n    </tr>\n    <tr>\n      <th>1697</th>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>D06E</td>\n    </tr>\n    <tr>\n      <th>1698</th>\n      <td>09BF5150</td>\n      <td>C7E19</td>\n      <td>D06E</td>\n    </tr>\n    <tr>\n      <th>1699</th>\n      <td>D410C91A</td>\n      <td>ACD06</td>\n      <td>9203</td>\n    </tr>\n  </tbody>\n</table>\n<p>1700 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Accuracy on each level (4 marks)\n",
    "Now you have the predictions for each level (in the test data), and you also have the actual levels, you can compute the accurcay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVEL 1 ACCURACY:  0.6717647058823529\n"
     ]
    }
   ],
   "source": [
    "# Level 1 accuracy\n",
    "print('LEVEL 1 ACCURACY: ', accuracy_score(y_test['Level_1'], level1_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVEL 2 ACCURACY:  0.6052941176470589\n"
     ]
    }
   ],
   "source": [
    "# Level 2 accuracy\n",
    "print('LEVEL 2 ACCURACY: ', accuracy_score(y_test['Level_2'], results['Level2_Pred']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LEVEL 3 ACCURACY:  0.26294117647058823\n"
     ]
    }
   ],
   "source": [
    "# Level 3 accuracy\n",
    "print('LEVEL 3 ACCURACY: ', accuracy_score(y_test['Level_3'], results['Level3_Pred']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well done!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python396jvsc74a57bd0b874ae6ca3bf8380d01ff748c279caa87bf096af67f0e2a4c58ac8b205c3f032",
   "display_name": "Python 3.9.6 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "b874ae6ca3bf8380d01ff748c279caa87bf096af67f0e2a4c58ac8b205c3f032"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}